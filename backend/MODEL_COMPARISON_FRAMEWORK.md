# Framework de Comparaison de Mod√®les ML pour le Trading

## üéØ Vue d'ensemble

Ce framework fournit un syst√®me complet pour comparer diff√©rents mod√®les d'apprentissage automatique dans le contexte du trading financier. Il permet d'√©valuer les performances de multiples mod√®les ML et de s√©lectionner automatiquement le meilleur selon diff√©rents crit√®res.

## üöÄ Fonctionnalit√©s

### Mod√®les Support√©s
- **Random Forest** : Mod√®le d'ensemble robuste et interpr√©table
- **XGBoost** : Gradient boosting optimis√© pour les performances
- **LightGBM** : Gradient boosting rapide et efficace
- **Neural Networks** : R√©seaux de neurones multi-couches
- **Mod√®les personnalis√©s** : Possibilit√© d'ajouter vos propres mod√®les

### M√©triques d'√âvaluation
- **M√©triques ML** : Accuracy, Precision, Recall, F1-Score, ROC-AUC
- **M√©triques de Trading** : Sharpe Ratio, Max Drawdown, Total Return, Win Rate, Profit Factor
- **M√©triques Temporelles** : Temps d'entra√Ænement, Temps de pr√©diction

### Fonctionnalit√©s Avanc√©es
- **Validation crois√©e temporelle** : √âvite le data leakage
- **Backtesting int√©gr√©** : Simulation de trading r√©aliste
- **Recommandations automatiques** : Suggestions de mod√®les bas√©es sur les caract√©ristiques du symbole
- **Comparaison multi-symboles** : Analyse agr√©g√©e sur plusieurs actifs
- **Rapports d√©taill√©s** : G√©n√©ration automatique de rapports de performance

## üìÅ Structure du Code

```
backend/app/services/
‚îú‚îÄ‚îÄ model_comparison_framework.py    # Framework principal
‚îú‚îÄ‚îÄ model_comparison_service.py      # Service d'int√©gration
‚îî‚îÄ‚îÄ ...

backend/app/api/endpoints/
‚îî‚îÄ‚îÄ model_comparison.py             # Endpoints API

backend/
‚îú‚îÄ‚îÄ test_model_comparison_framework.py  # Script de test
‚îú‚îÄ‚îÄ install_model_comparison_deps.sh    # Script d'installation
‚îî‚îÄ‚îÄ ...
```

## üõ†Ô∏è Installation

### 1. Installer les d√©pendances

```bash
cd backend
chmod +x install_model_comparison_deps.sh
./install_model_comparison_deps.sh
```

### 2. V√©rifier l'installation

```bash
python test_model_comparison_framework.py
```

## üîß Utilisation

### Utilisation via API

#### 1. Obtenir les mod√®les disponibles
```bash
curl -X GET "http://localhost:8000/api/v1/model-comparison/available-models"
```

#### 2. Comparer les mod√®les pour un symbole
```bash
curl -X POST "http://localhost:8000/api/v1/model-comparison/compare-single" \
  -H "Content-Type: application/json" \
  -d '{
    "symbol": "AAPL",
    "models_to_test": ["RandomForest", "XGBoost"],
    "start_date": "2023-01-01",
    "end_date": "2023-12-31"
  }'
```

#### 3. Obtenir des recommandations
```bash
curl -X POST "http://localhost:8000/api/v1/model-comparison/recommendations" \
  -H "Content-Type: application/json" \
  -d '{"symbol": "AAPL"}'
```

### Utilisation en Python

```python
from app.services.model_comparison_service import ModelComparisonService
from app.core.database import get_db

# Cr√©er le service
db = next(get_db())
service = ModelComparisonService(db)

# Comparer les mod√®les pour un symbole
result = service.compare_models_for_symbol(
    symbol="AAPL",
    models_to_test=["RandomForest", "XGBoost", "LightGBM"]
)

# Obtenir le meilleur mod√®le
if result['success']:
    best_model = result['best_model']
    print(f"Meilleur mod√®le: {best_model['name']}")
    print(f"F1-Score: {best_model['metrics']['f1_score']:.3f}")
```

## üìä Exemple de R√©sultats

### Rapport de Comparaison
```
================================================================================
RAPPORT DE COMPARAISON DE MOD√àLES
================================================================================
Date: 2024-01-15 14:30:25
Nombre de mod√®les compar√©s: 4

R√âSULTATS D√âTAILL√âS:
--------------------------------------------------------------------------------
Mod√®le                Accuracy   F1-Score   Sharpe     Return    
--------------------------------------------------------------------------------
RandomForest          0.756      0.742      1.234      0.156      
XGBoost              0.789      0.801      1.456      0.189      
LightGBM             0.782      0.795      1.389      0.178      
NeuralNetwork         0.734      0.728      1.123      0.134      
--------------------------------------------------------------------------------

MEILLEURS MOD√àLES PAR M√âTRIQUE:
----------------------------------------
Accuracy: XGBoost (0.789)
F1_score: XGBoost (0.801)
Sharpe: XGBoost (1.456)
Total_return: XGBoost (0.189)
```

## üéõÔ∏è Configuration

### Param√®tres des Mod√®les

#### Random Forest
```python
RandomForestModel(
    name='CustomRF',
    n_estimators=200,      # Nombre d'arbres
    max_depth=10,         # Profondeur maximale
    min_samples_split=5,  # √âchantillons minimum pour diviser
    min_samples_leaf=2    # √âchantillons minimum par feuille
)
```

#### XGBoost
```python
XGBoostModel(
    name='CustomXGB',
    n_estimators=200,        # Nombre d'estimateurs
    max_depth=8,             # Profondeur maximale
    learning_rate=0.05,      # Taux d'apprentissage
    subsample=0.8,          # Fraction d'√©chantillons
    colsample_bytree=0.8    # Fraction de features
)
```

### Personnalisation des Features

Le framework utilise automatiquement les donn√©es disponibles :
- **Donn√©es historiques** : Prix, volumes, OHLC
- **Indicateurs techniques** : SMA, EMA, RSI, MACD, Bollinger Bands, etc.
- **Indicateurs de sentiment** : Score de sentiment, momentum, volatilit√©, etc.

## üîç D√©bogage

### Logs
Le framework g√©n√®re des logs d√©taill√©s pour le d√©bogage :
```python
import logging
logging.basicConfig(level=logging.INFO)
```

### Tests
Ex√©cutez les tests pour v√©rifier le bon fonctionnement :
```bash
python test_model_comparison_framework.py
```

### V√©rification de la Sant√©
```bash
curl -X GET "http://localhost:8000/api/v1/model-comparison/health"
```

## üìà Performance

### Optimisations
- **Parall√©lisation** : Utilisation de `n_jobs=-1` pour les mod√®les support√©s
- **Mise en cache** : Sauvegarde automatique des r√©sultats
- **Validation temporelle** : √âvite le data leakage
- **Features engineering** : Calcul automatique des indicateurs

### Limitations
- **M√©moire** : Les gros datasets peuvent n√©cessiter plus de RAM
- **Temps** : L'entra√Ænement peut prendre du temps sur de gros datasets
- **D√©pendances** : XGBoost et LightGBM sont optionnels

## ü§ù Contribution

### Ajouter un Nouveau Mod√®le

1. Cr√©er une classe h√©ritant de `BaseModel`
2. Impl√©menter la m√©thode `_create_model()`
3. Ajouter le mod√®le au framework

```python
class CustomModel(BaseModel):
    def _create_model(self):
        return YourCustomClassifier(**self.parameters)

# Ajouter au framework
framework.add_model('CustomModel', CustomModel('CustomModel'))
```

### Am√©liorer les M√©triques

Les m√©triques de trading peuvent √™tre personnalis√©es en modifiant la m√©thode `_calculate_trading_metrics()`.

## üìö R√©f√©rences

- [Scikit-learn Documentation](https://scikit-learn.org/)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)

## üêõ Support

Pour signaler des bugs ou demander des fonctionnalit√©s :
1. V√©rifiez les logs pour les erreurs
2. Ex√©cutez les tests pour identifier les probl√®mes
3. Consultez la documentation des d√©pendances

---

**Note** : Ce framework est con√ßu pour √™tre extensible et modulaire. N'h√©sitez pas √† l'adapter √† vos besoins sp√©cifiques !
