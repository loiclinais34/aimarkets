#!/usr/bin/env python3
"""
Script de test pour v√©rifier l'API PLTR et diagnostiquer le probl√®me frontend
"""

import requests
import json

def test_pltr_api_detailed():
    base_url = "http://localhost:8000/api/v1/backtesting"
    
    print("üîç Diagnostic d√©taill√© de l'API PLTR")
    print("=" * 60)
    
    # 1. Test de la liste des symboles
    print("1. Test de la liste des symboles...")
    try:
        response = requests.get(f"{base_url}/symbols", timeout=10)
        if response.status_code == 200:
            data = response.json()
            pltr_symbol = None
            for symbol in data.get('symbols', []):
                if symbol['symbol'] == 'PLTR':
                    pltr_symbol = symbol
                    break
            
            if pltr_symbol:
                print(f"‚úÖ PLTR trouv√©: {pltr_symbol['prediction_count']} pr√©dictions, {pltr_symbol['model_count']} mod√®les")
            else:
                print("‚ùå PLTR non trouv√© dans la liste des symboles")
                return False
        else:
            print(f"‚ùå Erreur HTTP {response.status_code}: {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False
    
    # 2. Test de la r√©cup√©ration des mod√®les PLTR
    print("\n2. Test de la r√©cup√©ration des mod√®les PLTR...")
    try:
        response = requests.get(f"{base_url}/symbols/PLTR/models", timeout=30)
        if response.status_code == 200:
            data = response.json()
            models = data.get('models', [])
            print(f"‚úÖ {len(models)} mod√®les r√©cup√©r√©s pour PLTR")
            
            # Analyser les mod√®les
            if models:
                prediction_counts = [m['prediction_count'] for m in models]
                max_predictions = max(prediction_counts)
                min_predictions = min(prediction_counts)
                avg_predictions = sum(prediction_counts) / len(prediction_counts)
                
                print(f"üìä Statistiques des pr√©dictions:")
                print(f"   - Maximum: {max_predictions}")
                print(f"   - Minimum: {min_predictions}")
                print(f"   - Moyenne: {avg_predictions:.1f}")
                
                # Trouver les mod√®les avec le plus de pr√©dictions
                top_models = sorted(models, key=lambda x: x['prediction_count'], reverse=True)[:5]
                print(f"\nüèÜ Top 5 mod√®les avec le plus de pr√©dictions:")
                for i, model in enumerate(top_models, 1):
                    print(f"   {i}. {model['name']} - {model['prediction_count']} pr√©dictions")
                
                return True
            else:
                print("‚ùå Aucun mod√®le retourn√©")
                return False
        else:
            print(f"‚ùå Erreur HTTP {response.status_code}: {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå Erreur: {e}")
        return False

if __name__ == "__main__":
    success = test_pltr_api_detailed()
    if success:
        print("\nüéâ L'API fonctionne parfaitement ! Le probl√®me vient du frontend.")
        print("üí° Solutions possibles:")
        print("   1. Vider le cache du navigateur (Ctrl+F5)")
        print("   2. Red√©marrer le serveur frontend")
        print("   3. V√©rifier la console du navigateur pour les erreurs JavaScript")
    else:
        print("\nüí• Des erreurs ont √©t√© d√©tect√©es dans l'API.")
