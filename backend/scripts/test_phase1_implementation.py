#!/usr/bin/env python3
"""
Script de test pour la Phase 1: Am√©lioration des seuils de d√©cision
Teste les nouvelles pond√©rations, seuils et r√®gles de validation
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import pandas as pd
import numpy as np
from sqlalchemy.orm import Session
from app.core.database import get_db
from app.services.advanced_analysis.advanced_trading_analysis import AdvancedTradingAnalysis
import logging
from typing import Dict, List
import json
from datetime import datetime, date

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Phase1Tester:
    """Testeur pour la Phase 1 d'am√©lioration des seuils de d√©cision"""
    
    def __init__(self, db: Session):
        self.db = db
        self.analysis_service = AdvancedTradingAnalysis()
        self.results = {}
    
    def test_composite_score_formula(self) -> Dict:
        """Teste la nouvelle formule de composite_score"""
        logger.info("üßÆ Test de la nouvelle formule de composite_score")
        
        # Cas de test avec diff√©rents scores
        test_cases = [
            {
                "name": "Scores √©lev√©s",
                "technical": 0.8,
                "sentiment": 0.7,
                "market": 0.6,
                "expected_range": (0.65, 0.75)
            },
            {
                "name": "Scores moyens",
                "technical": 0.6,
                "sentiment": 0.5,
                "market": 0.4,
                "expected_range": (0.45, 0.55)
            },
            {
                "name": "Scores faibles",
                "technical": 0.3,
                "sentiment": 0.2,
                "market": 0.1,
                "expected_range": (0.15, 0.25)
            },
            {
                "name": "Scores mixtes",
                "technical": 0.9,
                "sentiment": 0.3,
                "market": 0.7,
                "expected_range": (0.60, 0.70)
            }
        ]
        
        results = []
        for case in test_cases:
            # Calculer le score composite avec la nouvelle formule
            composite_score = self.analysis_service._calculate_composite_score(
                case["technical"], case["sentiment"], case["market"], 0.0,
                0.0, 0.0, 0.0, 0.0, 0.0  # Scores avanc√©s d√©sactiv√©s
            )
            
            # V√©rifier si le score est dans la plage attendue
            in_range = case["expected_range"][0] <= composite_score <= case["expected_range"][1]
            
            results.append({
                "case": case["name"],
                "technical": case["technical"],
                "sentiment": case["sentiment"],
                "market": case["market"],
                "composite_score": composite_score,
                "expected_range": case["expected_range"],
                "in_range": in_range
            })
        
        return {
            "test_cases": results,
            "formula_working": all(r["in_range"] for r in results)
        }
    
    def test_decision_thresholds(self) -> Dict:
        """Teste les nouveaux seuils de d√©cision"""
        logger.info("üéØ Test des nouveaux seuils de d√©cision")
        
        # Cas de test pour chaque cat√©gorie
        test_cases = [
            {
                "name": "BUY_STRONG",
                "composite": 0.70,
                "technical": 0.65,
                "sentiment": 0.55,
                "market": 0.45,
                "confidence": 0.85,
                "expected_recommendation": "BUY_STRONG"
            },
            {
                "name": "BUY_MODERATE",
                "composite": 0.60,
                "technical": 0.55,
                "sentiment": 0.45,
                "market": 0.35,
                "confidence": 0.70,
                "expected_recommendation": "BUY_MODERATE"
            },
            {
                "name": "BUY_WEAK",
                "composite": 0.50,
                "technical": 0.45,
                "sentiment": 0.35,
                "market": 0.25,
                "confidence": 0.50,
                "expected_recommendation": "BUY_WEAK"
            },
            {
                "name": "HOLD",
                "composite": 0.40,
                "technical": 0.35,
                "sentiment": 0.25,
                "market": 0.15,
                "confidence": 0.30,
                "expected_recommendation": "HOLD"
            },
            {
                "name": "SELL_MODERATE",
                "composite": 0.30,
                "technical": 0.25,
                "sentiment": 0.15,
                "market": 0.05,
                "confidence": 0.20,
                "expected_recommendation": "SELL_MODERATE"
            },
            {
                "name": "SELL_STRONG",
                "composite": 0.20,
                "technical": 0.15,
                "sentiment": 0.05,
                "market": 0.0,
                "confidence": 0.10,
                "expected_recommendation": "SELL_STRONG"
            }
        ]
        
        results = []
        for case in test_cases:
            # Tester la d√©termination de recommandation
            recommendation, risk_level = self.analysis_service._determine_recommendation(
                case["composite"], case["technical"], case["sentiment"], 
                case["market"], case["confidence"]
            )
            
            # V√©rifier si la recommandation est correcte
            correct = recommendation == case["expected_recommendation"]
            
            results.append({
                "case": case["name"],
                "composite": case["composite"],
                "technical": case["technical"],
                "sentiment": case["sentiment"],
                "market": case["market"],
                "confidence": case["confidence"],
                "recommendation": recommendation,
                "risk_level": risk_level,
                "expected": case["expected_recommendation"],
                "correct": correct
            })
        
        return {
            "test_cases": results,
            "thresholds_working": all(r["correct"] for r in results)
        }
    
    def test_validation_rules(self) -> Dict:
        """Teste les r√®gles de validation"""
        logger.info("‚úÖ Test des r√®gles de validation")
        
        # Cas de test pour les r√®gles de validation
        test_cases = [
            {
                "name": "BUY_STRONG - Validation r√©ussie",
                "composite": 0.70,
                "technical": 0.65,
                "sentiment": 0.55,
                "market": 0.45,
                "confidence": 0.85,
                "expected_validation": True
            },
            {
                "name": "BUY_STRONG - √âchec technique",
                "composite": 0.70,
                "technical": 0.55,  # Trop faible
                "sentiment": 0.55,
                "market": 0.45,
                "confidence": 0.85,
                "expected_validation": False
            },
            {
                "name": "BUY_STRONG - √âchec confiance",
                "composite": 0.70,
                "technical": 0.65,
                "sentiment": 0.55,
                "market": 0.45,
                "confidence": 0.75,  # Trop faible
                "expected_validation": False
            },
            {
                "name": "BUY_MODERATE - Validation r√©ussie",
                "composite": 0.60,
                "technical": 0.55,
                "sentiment": 0.45,
                "market": 0.35,
                "confidence": 0.70,
                "expected_validation": True
            },
            {
                "name": "BUY_WEAK - Validation r√©ussie",
                "composite": 0.50,
                "technical": 0.45,
                "sentiment": 0.35,
                "market": 0.25,
                "confidence": 0.50,
                "expected_validation": True
            }
        ]
        
        results = []
        for case in test_cases:
            # Tester la validation
            validation = self.analysis_service._validate_buy_signals(
                case["composite"], case["technical"], case["sentiment"],
                case["market"], case["confidence"]
            )
            
            # D√©terminer quelle cat√©gorie devrait √™tre valid√©e
            if case["composite"] >= 0.65:
                expected_category = "BUY_STRONG"
            elif case["composite"] >= 0.55:
                expected_category = "BUY_MODERATE"
            elif case["composite"] >= 0.45:
                expected_category = "BUY_WEAK"
            else:
                expected_category = "NONE"
            
            # V√©rifier la validation
            validation_passed = validation.get(expected_category, False) if expected_category != "NONE" else True
            correct = validation_passed == case["expected_validation"]
            
            results.append({
                "case": case["name"],
                "composite": case["composite"],
                "technical": case["technical"],
                "sentiment": case["sentiment"],
                "market": case["market"],
                "confidence": case["confidence"],
                "validation": validation,
                "expected_category": expected_category,
                "validation_passed": validation_passed,
                "expected_validation": case["expected_validation"],
                "correct": correct
            })
        
        return {
            "test_cases": results,
            "validation_working": all(r["correct"] for r in results)
        }
    
    async def test_real_symbol_analysis(self) -> Dict:
        """Teste l'analyse sur un symbole r√©el"""
        logger.info("üìä Test d'analyse sur symbole r√©el")
        
        # Test sur quelques symboles
        test_symbols = ["AAPL", "MSFT", "GOOGL", "TSLA", "NVDA"]
        results = []
        
        for symbol in test_symbols:
            try:
                # Analyser le symbole
                analysis_result = await self.analysis_service.analyze_opportunity(symbol, db=self.db)
                
                results.append({
                    "symbol": symbol,
                    "technical_score": analysis_result.technical_score,
                    "sentiment_score": analysis_result.sentiment_score,
                    "market_score": analysis_result.market_score,
                    "composite_score": analysis_result.composite_score,
                    "confidence_level": analysis_result.confidence_level,
                    "recommendation": analysis_result.recommendation,
                    "risk_level": analysis_result.risk_level,
                    "analysis_successful": True
                })
                
            except Exception as e:
                results.append({
                    "symbol": symbol,
                    "error": str(e),
                    "analysis_successful": False
                })
        
        return {
            "symbol_analyses": results,
            "successful_analyses": sum(1 for r in results if r.get("analysis_successful", False))
        }
    
    async def run_complete_test(self) -> Dict:
        """Ex√©cute tous les tests de la Phase 1"""
        logger.info("üöÄ D√©marrage des tests complets de la Phase 1")
        
        try:
            self.results = {
                "composite_score_test": self.test_composite_score_formula(),
                "decision_thresholds_test": self.test_decision_thresholds(),
                "validation_rules_test": self.test_validation_rules(),
                "real_symbol_test": await self.test_real_symbol_analysis(),
                "test_timestamp": datetime.now().isoformat()
            }
            
            return self.results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors des tests: {e}")
            raise
    
    def print_summary(self):
        """Affiche un r√©sum√© des tests"""
        if not self.results:
            logger.warning("Aucun r√©sultat de test √† afficher")
            return
        
        composite_test = self.results["composite_score_test"]
        thresholds_test = self.results["decision_thresholds_test"]
        validation_test = self.results["validation_rules_test"]
        real_test = self.results["real_symbol_test"]
        
        print("\n" + "="*80)
        print("üß™ R√âSULTATS DES TESTS - PHASE 1: AM√âLIORATION DES SEUILS DE D√âCISION")
        print("="*80)
        
        print(f"\nüßÆ TEST DE LA FORMULE COMPOSITE_SCORE:")
        print(f"  ‚Ä¢ Formule fonctionnelle: {'‚úÖ' if composite_test['formula_working'] else '‚ùå'}")
        for case in composite_test["test_cases"]:
            status = "‚úÖ" if case["in_range"] else "‚ùå"
            print(f"    {status} {case['case']}: {case['composite_score']:.3f} (attendu: {case['expected_range']})")
        
        print(f"\nüéØ TEST DES SEUILS DE D√âCISION:")
        print(f"  ‚Ä¢ Seuils fonctionnels: {'‚úÖ' if thresholds_test['thresholds_working'] else '‚ùå'}")
        for case in thresholds_test["test_cases"]:
            status = "‚úÖ" if case["correct"] else "‚ùå"
            print(f"    {status} {case['case']}: {case['recommendation']} (attendu: {case['expected']})")
        
        print(f"\n‚úÖ TEST DES R√àGLES DE VALIDATION:")
        print(f"  ‚Ä¢ Validation fonctionnelle: {'‚úÖ' if validation_test['validation_working'] else '‚ùå'}")
        for case in validation_test["test_cases"]:
            status = "‚úÖ" if case["correct"] else "‚ùå"
            print(f"    {status} {case['case']}: Validation {'r√©ussie' if case['validation_passed'] else '√©chou√©e'}")
        
        print(f"\nüìä TEST D'ANALYSE R√âELLE:")
        print(f"  ‚Ä¢ Analyses r√©ussies: {real_test['successful_analyses']}/{len(real_test['symbol_analyses'])}")
        for case in real_test["symbol_analyses"]:
            if case.get("analysis_successful", False):
                print(f"    ‚úÖ {case['symbol']}: {case['recommendation']} (score: {case['composite_score']:.3f})")
            else:
                print(f"    ‚ùå {case['symbol']}: {case.get('error', 'Erreur inconnue')}")
        
        # R√©sum√© global
        all_tests_passed = (
            composite_test['formula_working'] and
            thresholds_test['thresholds_working'] and
            validation_test['validation_working'] and
            real_test['successful_analyses'] > 0
        )
        
        print(f"\nüéâ R√âSULTAT GLOBAL:")
        print(f"  ‚Ä¢ Phase 1 impl√©ment√©e avec succ√®s: {'‚úÖ' if all_tests_passed else '‚ùå'}")
        
        print("\n" + "="*80)


async def main():
    """Fonction principale"""
    
    logger.info("üöÄ D√©marrage des tests de la Phase 1")
    
    db = next(get_db())
    
    try:
        # Cr√©er le testeur
        tester = Phase1Tester(db)
        
        # Ex√©cuter les tests
        results = await tester.run_complete_test()
        
        # Afficher le r√©sum√©
        tester.print_summary()
        
        # Sauvegarder les r√©sultats
        output_file = os.path.join(os.path.dirname(__file__), "phase1_test_results.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"üìÅ R√©sultats de test sauvegard√©s dans {output_file}")
        logger.info("‚úÖ Tests de la Phase 1 termin√©s avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution des tests: {e}")
        import traceback
        traceback.print_exc()
        raise
    finally:
        db.close()


if __name__ == "__main__":
    asyncio.run(main())
