#!/usr/bin/env python3
"""
Script d'optimisation des signaux d'achat
Propose des am√©liorations concr√®tes bas√©es sur l'analyse des opportunit√©s d'achat
"""
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import json
import pandas as pd
import numpy as np
from typing import Dict, List, Tuple
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class BuySignalOptimizer:
    """Optimiseur des signaux d'achat"""
    
    def __init__(self, analysis_file: str = "buy_opportunities_analysis.json"):
        self.analysis_file = os.path.join(os.path.dirname(__file__), analysis_file)
        self.data = self.load_analysis_data()
    
    def load_analysis_data(self) -> Dict:
        """Charge les donn√©es d'analyse"""
        try:
            with open(self.analysis_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"Fichier d'analyse non trouv√©: {self.analysis_file}")
            return {}
    
    def analyze_current_performance(self) -> Dict:
        """Analyse la performance actuelle des signaux d'achat"""
        logger.info("üìä Analyse de la performance actuelle")
        
        recommendations = self.data.get("improvement_recommendations", {})
        current_perf = recommendations.get("current_performance", {})
        
        issues = []
        strengths = []
        
        # Analyser les probl√®mes
        success_rate = current_perf.get("success_rate", 0)
        avg_return = current_perf.get("avg_return", 0)
        
        if success_rate < 60:
            issues.append(f"Taux de succ√®s trop faible: {success_rate:.1f}% (objectif: >60%)")
        
        if avg_return < 0:
            issues.append(f"Retour moyen n√©gatif: {avg_return:.2f}% (objectif: >0%)")
        
        # Analyser les forces
        if success_rate > 50:
            strengths.append(f"Taux de succ√®s acceptable: {success_rate:.1f}%")
        
        return {
            "current_performance": current_perf,
            "issues": issues,
            "strengths": strengths,
            "improvement_potential": {
                "success_rate_target": 65,
                "avg_return_target": 0.5,
                "precision_target": 70
            }
        }
    
    def propose_improved_scoring(self) -> Dict:
        """Propose un syst√®me de scoring am√©lior√©"""
        logger.info("üéØ Proposition de scoring am√©lior√©")
        
        threshold_analysis = self.data.get("threshold_analysis", {})
        combinations = self.data.get("indicator_combinations", {})
        
        # Analyser les seuils optimaux
        optimal_thresholds = {}
        for score, analysis in threshold_analysis.items():
            if "best_threshold" in analysis and analysis["best_threshold"] is not None:
                optimal_thresholds[score] = analysis["best_threshold"]
        
        # Analyser les meilleures combinaisons
        best_combinations = combinations.get("combinations", [])[:3]
        
        # Proposer un nouveau syst√®me de scoring
        improved_scoring = {
            "composite_score_formula": {
                "description": "Formule am√©lior√©e bas√©e sur les meilleures combinaisons",
                "formula": "0.4 * technical_score + 0.35 * sentiment_score + 0.25 * market_score",
                "rationale": "Pond√©ration bas√©e sur les corr√©lations avec le succ√®s"
            },
            "decision_thresholds": {
                "BUY_STRONG": {
                    "min_composite_score": 0.65,
                    "min_technical_score": 0.6,
                    "min_sentiment_score": 0.5,
                    "min_market_score": 0.4,
                    "min_confidence": 0.8,
                    "description": "Signaux tr√®s forts avec confirmation multiple"
                },
                "BUY_MODERATE": {
                    "min_composite_score": 0.55,
                    "min_technical_score": 0.5,
                    "min_sentiment_score": 0.4,
                    "min_market_score": 0.3,
                    "min_confidence": 0.6,
                    "description": "Signaux mod√©r√©s avec validation partielle"
                },
                "BUY_WEAK": {
                    "min_composite_score": 0.45,
                    "min_technical_score": 0.4,
                    "min_sentiment_score": 0.3,
                    "min_market_score": 0.2,
                    "min_confidence": 0.4,
                    "description": "Signaux faibles - surveillance uniquement"
                }
            },
            "validation_rules": {
                "technical_validation": [
                    "RSI entre 30 et 70 (√©viter les extr√™mes)",
                    "MACD au-dessus de la ligne de signal",
                    "Prix au-dessus de la moyenne mobile 20",
                    "Volume sup√©rieur √† la moyenne sur 20 jours"
                ],
                "sentiment_validation": [
                    "Score de sentiment > 0.5",
                    "Confiance du sentiment > 0.6",
                    "Tendance du sentiment positive sur 5 jours"
                ],
                "market_validation": [
                    "R√©gime de march√© favorable",
                    "Volatilit√© dans une fourchette acceptable",
                    "Corr√©lations sectorielles positives"
                ]
            }
        }
        
        return improved_scoring
    
    def propose_risk_management(self) -> Dict:
        """Propose un syst√®me de gestion du risque am√©lior√©"""
        logger.info("‚ö†Ô∏è Proposition de gestion du risque")
        
        risk_analysis = self.data.get("risk_analysis", {})
        confidence_analysis = self.data.get("confidence_analysis", {})
        
        risk_management = {
            "position_sizing": {
                "BUY_STRONG": {
                    "base_size": 100,
                    "max_size": 150,
                    "risk_multiplier": 1.0,
                    "description": "Positions normales pour signaux forts"
                },
                "BUY_MODERATE": {
                    "base_size": 75,
                    "max_size": 100,
                    "risk_multiplier": 0.75,
                    "description": "Positions r√©duites pour signaux mod√©r√©s"
                },
                "BUY_WEAK": {
                    "base_size": 25,
                    "max_size": 50,
                    "risk_multiplier": 0.25,
                    "description": "Positions minimales pour signaux faibles"
                }
            },
            "stop_loss": {
                "BUY_STRONG": {
                    "stop_loss": -3.0,
                    "trailing_stop": -2.0,
                    "description": "Stops plus larges pour signaux forts"
                },
                "BUY_MODERATE": {
                    "stop_loss": -2.5,
                    "trailing_stop": -1.5,
                    "description": "Stops standards pour signaux mod√©r√©s"
                },
                "BUY_WEAK": {
                    "stop_loss": -2.0,
                    "trailing_stop": -1.0,
                    "description": "Stops serr√©s pour signaux faibles"
                }
            },
            "take_profit": {
                "BUY_STRONG": {
                    "take_profit": 8.0,
                    "partial_profit": 4.0,
                    "description": "Objectifs √©lev√©s pour signaux forts"
                },
                "BUY_MODERATE": {
                    "take_profit": 6.0,
                    "partial_profit": 3.0,
                    "description": "Objectifs mod√©r√©s pour signaux mod√©r√©s"
                },
                "BUY_WEAK": {
                    "take_profit": 4.0,
                    "partial_profit": 2.0,
                    "description": "Objectifs conservateurs pour signaux faibles"
                }
            },
            "portfolio_limits": {
                "max_positions": 10,
                "max_sector_exposure": 30,
                "max_single_position": 15,
                "cash_reserve": 20
            }
        }
        
        return risk_management
    
    def propose_ml_improvements(self) -> Dict:
        """Propose des am√©liorations ML sp√©cifiques aux signaux d'achat"""
        logger.info("ü§ñ Proposition d'am√©liorations ML")
        
        ml_improvements = {
            "feature_engineering": {
                "technical_features": [
                    "RSI normalis√© (0-1)",
                    "MACD momentum (5, 10, 20 jours)",
                    "Bollinger Bands position",
                    "Volume ratio (actuel/moyenne)",
                    "Support/resistance proximity",
                    "Trend strength (ADX)",
                    "Volatility percentile"
                ],
                "sentiment_features": [
                    "Sentiment score normalis√©",
                    "Sentiment confidence",
                    "Sentiment trend (5, 10 jours)",
                    "Sentiment volatility",
                    "News sentiment ratio",
                    "Social media sentiment"
                ],
                "market_features": [
                    "Market regime indicator",
                    "Sector rotation signal",
                    "Market volatility",
                    "Correlation with market",
                    "Beta coefficient",
                    "Liquidity indicator"
                ],
                "temporal_features": [
                    "Day of week effect",
                    "Month of year effect",
                    "Earnings proximity",
                    "Dividend proximity",
                    "Options expiration proximity"
                ]
            },
            "model_architecture": {
                "primary_model": "XGBoost avec validation crois√©e temporelle",
                "secondary_model": "Neural Network pour interactions complexes",
                "ensemble_method": "Stacking avec m√©ta-apprentissage",
                "confidence_model": "S√©par√© pour estimer la fiabilit√© des pr√©dictions"
            },
            "training_strategy": {
                "validation": "TimeSeriesSplit avec 5 folds",
                "metrics": "F1-score pond√©r√© + Sharpe ratio + Precision",
                "regularization": "Early stopping + L1/L2 + Dropout",
                "hyperparameter_tuning": "Optuna avec 100 trials"
            },
            "class_balancing": {
                "technique": "SMOTE + Undersampling",
                "target_distribution": {
                    "BUY_STRONG": 40,
                    "BUY_MODERATE": 35,
                    "BUY_WEAK": 25
                },
                "description": "√âquilibrer les classes pour √©viter le biais"
            }
        }
        
        return ml_improvements
    
    def propose_implementation_plan(self) -> Dict:
        """Propose un plan d'impl√©mentation pour les am√©liorations"""
        logger.info("üìã Proposition de plan d'impl√©mentation")
        
        plan = {
            "phase_1": {
                "title": "Am√©lioration des seuils de d√©cision",
                "duration": "1 semaine",
                "tasks": [
                    "Impl√©menter les nouveaux seuils de composite_score",
                    "Ajuster la logique de classification BUY_STRONG/MODERATE/WEAK",
                    "Tester sur les donn√©es historiques",
                    "Valider les performances"
                ],
                "expected_improvement": "R√©duction du nombre d'opportunit√©s mais am√©lioration de la qualit√©",
                "success_metrics": ["Taux de succ√®s > 60%", "Retour moyen > 0%"]
            },
            "phase_2": {
                "title": "Am√©lioration du scoring",
                "duration": "2 semaines",
                "tasks": [
                    "Impl√©menter la nouvelle formule de composite_score",
                    "Ajouter les r√®gles de validation technique/sentiment/march√©",
                    "Int√©grer les niveaux de confiance",
                    "Tester sur backtesting"
                ],
                "expected_improvement": "Am√©lioration de la pr√©cision des signaux",
                "success_metrics": ["Pr√©cision > 70%", "F1-score > 0.65"]
            },
            "phase_3": {
                "title": "Gestion du risque",
                "duration": "1 semaine",
                "tasks": [
                    "Impl√©menter le position sizing adaptatif",
                    "Ajouter les stops et take-profits",
                    "Int√©grer les limites de portefeuille",
                    "Tester la gestion du risque"
                ],
                "expected_improvement": "Am√©lioration du ratio risque/rendement",
                "success_metrics": ["Sharpe ratio > 0.5", "Max drawdown < 10%"]
            },
            "phase_4": {
                "title": "Impl√©mentation ML",
                "duration": "3-4 semaines",
                "tasks": [
                    "D√©velopper le pipeline ML",
                    "Impl√©menter le feature engineering",
                    "Entra√Æner les mod√®les",
                    "Valider les performances"
                ],
                "expected_improvement": "Optimisation globale des performances",
                "success_metrics": ["Taux de succ√®s > 65%", "Retour moyen > 0.5%"]
            }
        }
        
        return plan
    
    def generate_actionable_recommendations(self) -> Dict:
        """G√©n√®re des recommandations actionnables imm√©diates"""
        logger.info("üí° G√©n√©ration de recommandations actionnables")
        
        recommendations = {
            "immediate_actions": [
                {
                    "action": "Augmenter le seuil minimum de composite_score",
                    "current": "0.5",
                    "proposed": "0.6",
                    "rationale": "Filtrer les opportunit√©s de moindre qualit√©",
                    "expected_impact": "R√©duction de 30% du nombre d'opportunit√©s mais am√©lioration de la qualit√©"
                },
                {
                    "action": "Impl√©menter un filtre de confiance",
                    "current": "Aucun",
                    "proposed": "Confiance > 0.7 pour BUY_STRONG",
                    "rationale": "Ne consid√©rer que les signaux avec une confiance √©lev√©e",
                    "expected_impact": "Am√©lioration de la pr√©cision de 10-15%"
                },
                {
                    "action": "Ajuster la pond√©ration du composite_score",
                    "current": "√âgale (0.33, 0.33, 0.33)",
                    "proposed": "Technique 0.4, Sentiment 0.35, March√© 0.25",
                    "rationale": "Bas√© sur les corr√©lations avec le succ√®s",
                    "expected_impact": "Am√©lioration de la pr√©cision de 5-10%"
                }
            ],
            "medium_term_actions": [
                {
                    "action": "Impl√©menter des r√®gles de validation",
                    "description": "Ajouter des contr√¥les techniques, sentiment et march√©",
                    "timeline": "2-3 semaines",
                    "expected_impact": "R√©duction des faux positifs de 20-30%"
                },
                {
                    "action": "D√©velopper un syst√®me de position sizing",
                    "description": "Ajuster la taille des positions selon la qualit√© du signal",
                    "timeline": "1-2 semaines",
                    "expected_impact": "Am√©lioration du ratio risque/rendement"
                },
                {
                    "action": "Mettre en place un syst√®me de monitoring",
                    "description": "Surveiller les performances en temps r√©el",
                    "timeline": "1 semaine",
                    "expected_impact": "D√©tection rapide des probl√®mes"
                }
            ],
            "long_term_actions": [
                {
                    "action": "D√©velopper un mod√®le ML d√©di√©",
                    "description": "Mod√®le sp√©cialis√© pour les signaux d'achat",
                    "timeline": "4-6 semaines",
                    "expected_impact": "Optimisation globale des performances"
                },
                {
                    "action": "Impl√©menter un syst√®me de validation crois√©e",
                    "description": "Validation temporelle pour √©viter le surapprentissage",
                    "timeline": "2-3 semaines",
                    "expected_impact": "Robustesse accrue des pr√©dictions"
                }
            ]
        }
        
        return recommendations
    
    def run_complete_analysis(self) -> Dict:
        """Ex√©cute l'analyse compl√®te d'optimisation"""
        logger.info("üöÄ D√©marrage de l'analyse d'optimisation compl√®te")
        
        try:
            self.results = {
                "current_performance": self.analyze_current_performance(),
                "improved_scoring": self.propose_improved_scoring(),
                "risk_management": self.propose_risk_management(),
                "ml_improvements": self.propose_ml_improvements(),
                "implementation_plan": self.propose_implementation_plan(),
                "actionable_recommendations": self.generate_actionable_recommendations()
            }
            
            return self.results
            
        except Exception as e:
            logger.error(f"‚ùå Erreur lors de l'analyse: {e}")
            raise
    
    def print_summary(self):
        """Affiche un r√©sum√© des optimisations propos√©es"""
        if not self.results:
            logger.warning("Aucun r√©sultat √† afficher")
            return
        
        current_perf = self.results["current_performance"]
        improved_scoring = self.results["improved_scoring"]
        risk_mgmt = self.results["risk_management"]
        recommendations = self.results["actionable_recommendations"]
        
        print("\n" + "="*80)
        print("üöÄ OPTIMISATION DES SIGNAUX D'ACHAT (BUY_STRONG & BUY_MODERATE)")
        print("="*80)
        
        print(f"\nüìä PERFORMANCE ACTUELLE:")
        if "current_performance" in current_perf:
            perf = current_perf["current_performance"]
            print(f"  ‚Ä¢ Taux de succ√®s: {perf.get('success_rate', 0):.1f}%")
            print(f"  ‚Ä¢ Retour moyen: {perf.get('avg_return', 0):.2f}%")
            print(f"  ‚Ä¢ Nombre d'opportunit√©s: {perf.get('total_opportunities', 0)}")
        
        print(f"\nüéØ NOUVEAUX SEUILS DE D√âCISION:")
        decision_thresholds = improved_scoring.get("decision_thresholds", {})
        for category, thresholds in decision_thresholds.items():
            print(f"  ‚Ä¢ {category}: composite_score ‚â• {thresholds.get('min_composite_score', 0):.2f}")
            print(f"    Description: {thresholds.get('description', '')}")
        
        print(f"\n‚ö†Ô∏è GESTION DU RISQUE:")
        position_sizing = risk_mgmt.get("position_sizing", {})
        for category, sizing in position_sizing.items():
            print(f"  ‚Ä¢ {category}: Taille de base {sizing.get('base_size', 0)}%")
            print(f"    Description: {sizing.get('description', '')}")
        
        print(f"\nüí° ACTIONS IMM√âDIATES:")
        immediate_actions = recommendations.get("immediate_actions", [])
        for i, action in enumerate(immediate_actions, 1):
            print(f"  {i}. {action['action']}")
            print(f"     Actuel: {action['current']} ‚Üí Propos√©: {action['proposed']}")
            print(f"     Impact attendu: {action['expected_impact']}")
        
        print(f"\nüìã PLAN D'IMPL√âMENTATION:")
        implementation_plan = self.results["implementation_plan"]
        for phase, details in implementation_plan.items():
            print(f"  {phase.upper()}: {details['title']}")
            print(f"    Dur√©e: {details['duration']}")
            print(f"    Am√©lioration attendue: {details['expected_improvement']}")
        
        print("\n" + "="*80)


def main():
    """Fonction principale"""
    
    logger.info("üöÄ D√©marrage de l'optimisation des signaux d'achat")
    
    try:
        # Cr√©er l'optimiseur
        optimizer = BuySignalOptimizer()
        
        # Ex√©cuter l'analyse
        results = optimizer.run_complete_analysis()
        
        # Afficher le r√©sum√©
        optimizer.print_summary()
        
        # Sauvegarder les r√©sultats
        output_file = os.path.join(os.path.dirname(__file__), "buy_signals_optimization.json")
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"üìÅ Optimisations sauvegard√©es dans {output_file}")
        logger.info("‚úÖ Optimisation des signaux d'achat termin√©e avec succ√®s")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur lors de l'ex√©cution: {e}")
        import traceback
        traceback.print_exc()
        raise


if __name__ == "__main__":
    main()
