#!/usr/bin/env python3
"""
Script pour calculer et stocker les corrÃ©lations
DÃ©veloppe des corrÃ©lations inter-variables et cross-asset selon le plan
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, date, timedelta
from pathlib import Path
import psycopg2
from psycopg2.extras import execute_values
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading
from scipy.stats import pearsonr, spearmanr, kendalltau
import warnings
warnings.filterwarnings('ignore')

# Ajouter le rÃ©pertoire parent au path pour les imports
sys.path.append(str(Path(__file__).parent.parent))

from app.core.config import settings

# Lock pour les opÃ©rations de base de donnÃ©es
db_lock = threading.Lock()

def get_all_symbols():
    """RÃ©cupÃ©rer TOUS les symboles disponibles"""
    conn = psycopg2.connect(
        host='localhost',
        port=5432,
        database='aimarkets',
        user='loiclinais',
        password='MonCoeur1703@'
    )
    
    try:
        query = """
        SELECT DISTINCT symbol 
        FROM historical_data 
        ORDER BY symbol
        """
        
        cursor = conn.cursor()
        cursor.execute(query)
        symbols = [row[0] for row in cursor.fetchall()]
        
        return symbols
    
    finally:
        conn.close()

def calculate_correlations_for_symbol(symbol: str, limit_per_symbol: int = 500):
    """Calculer les corrÃ©lations pour un symbole"""
    
    conn = psycopg2.connect(
        host='localhost',
        port=5432,
        database='aimarkets',
        user='loiclinais',
        password='MonCoeur1703@'
    )
    
    try:
        print(f"   ğŸ”„ Calcul des corrÃ©lations pour {symbol}...")
        
        # RÃ©cupÃ©rer les donnÃ©es historiques
        query_historical = """
        SELECT date, open, high, low, close, volume, vwap
        FROM historical_data 
        WHERE symbol = %s 
        ORDER BY date DESC
        LIMIT %s
        """
        
        df_historical = pd.read_sql(query_historical, conn, params=[symbol, limit_per_symbol])
        
        if df_historical.empty:
            return symbol, 0, f"Aucune donnÃ©e historique trouvÃ©e"
        
        # RÃ©cupÃ©rer les indicateurs techniques
        query_technical = """
        SELECT date, sma_5, sma_10, sma_20, sma_50, sma_200,
               ema_5, ema_10, ema_20, ema_50, ema_200,
               rsi_14, macd, macd_signal, macd_histogram,
               stochastic_k, stochastic_d, williams_r, roc, cci,
               bb_upper, bb_middle, bb_lower, bb_width, bb_position,
               obv, volume_roc, volume_sma_20, atr_14
        FROM technical_indicators 
        WHERE symbol = %s 
        ORDER BY date DESC
        LIMIT %s
        """
        
        df_technical = pd.read_sql(query_technical, conn, params=[symbol, limit_per_symbol])
        
        # RÃ©cupÃ©rer les indicateurs de sentiment
        query_sentiment = """
        SELECT date, sentiment_score_normalized, sentiment_momentum_7d, sentiment_volatility_14d,
               sentiment_rsi_14, sentiment_macd, news_positive_ratio, news_negative_ratio,
               sentiment_strength_index, market_sentiment_index, sentiment_risk_score, sentiment_quality_index
        FROM sentiment_indicators 
        WHERE symbol = %s 
        ORDER BY date DESC
        LIMIT %s
        """
        
        df_sentiment = pd.read_sql(query_sentiment, conn, params=[symbol, limit_per_symbol])
        
        # Fusionner les donnÃ©es
        df = df_historical.merge(df_technical, on='date', how='inner')
        df = df.merge(df_sentiment, on='date', how='inner')
        
        if df.empty:
            return symbol, 0, f"Aucune donnÃ©e fusionnÃ©e trouvÃ©e"
        
        # Trier par date croissante
        df = df.sort_values('date').reset_index(drop=True)
        
        # === CORRÃ‰LATIONS INTER-VARIABLES ===
        print(f"   ğŸ”„ Calcul des corrÃ©lations inter-variables...")
        
        # 1. CorrÃ©lations Prix-Volume
        price_volume_correlations = {}
        price_cols = ['open', 'high', 'low', 'close', 'vwap']
        volume_cols = ['volume', 'obv', 'volume_roc', 'volume_sma_20']
        
        for price_col in price_cols:
            for volume_col in volume_cols:
                if price_col in df.columns and volume_col in df.columns:
                    # Pearson
                    corr_pearson, p_val_pearson = pearsonr(df[price_col].dropna(), df[volume_col].dropna())
                    # Spearman
                    corr_spearman, p_val_spearman = spearmanr(df[price_col].dropna(), df[volume_col].dropna())
                    # Kendall
                    corr_kendall, p_val_kendall = kendalltau(df[price_col].dropna(), df[volume_col].dropna())
                    
                    price_volume_correlations[f'{price_col}_{volume_col}_pearson'] = corr_pearson
                    price_volume_correlations[f'{price_col}_{volume_col}_spearman'] = corr_spearman
                    price_volume_correlations[f'{price_col}_{volume_col}_kendall'] = corr_kendall
        
        # 2. CorrÃ©lations Technique-Sentiment
        technical_sentiment_correlations = {}
        technical_cols = ['rsi_14', 'macd', 'stochastic_k', 'williams_r', 'roc', 'cci', 'bb_position']
        sentiment_cols = ['sentiment_score_normalized', 'sentiment_momentum_7d', 'sentiment_volatility_14d',
                         'sentiment_rsi_14', 'sentiment_macd', 'news_positive_ratio', 'news_negative_ratio']
        
        for tech_col in technical_cols:
            for sent_col in sentiment_cols:
                if tech_col in df.columns and sent_col in df.columns:
                    # Pearson
                    corr_pearson, p_val_pearson = pearsonr(df[tech_col].dropna(), df[sent_col].dropna())
                    # Spearman
                    corr_spearman, p_val_spearman = spearmanr(df[tech_col].dropna(), df[sent_col].dropna())
                    # Kendall
                    corr_kendall, p_val_kendall = kendalltau(df[tech_col].dropna(), df[sent_col].dropna())
                    
                    technical_sentiment_correlations[f'{tech_col}_{sent_col}_pearson'] = corr_pearson
                    technical_sentiment_correlations[f'{tech_col}_{sent_col}_spearman'] = corr_spearman
                    technical_sentiment_correlations[f'{tech_col}_{sent_col}_kendall'] = corr_kendall
        
        # 3. CorrÃ©lations Sentiment-Volume
        sentiment_volume_correlations = {}
        sentiment_cols = ['sentiment_score_normalized', 'sentiment_momentum_7d', 'news_positive_ratio', 'news_negative_ratio']
        volume_cols = ['volume', 'obv', 'volume_roc', 'volume_sma_20']
        
        for sent_col in sentiment_cols:
            for vol_col in volume_cols:
                if sent_col in df.columns and vol_col in df.columns:
                    # Pearson
                    corr_pearson, p_val_pearson = pearsonr(df[sent_col].dropna(), df[vol_col].dropna())
                    # Spearman
                    corr_spearman, p_val_spearman = spearmanr(df[sent_col].dropna(), df[vol_col].dropna())
                    # Kendall
                    corr_kendall, p_val_kendall = kendalltau(df[sent_col].dropna(), df[vol_col].dropna())
                    
                    sentiment_volume_correlations[f'{sent_col}_{vol_col}_pearson'] = corr_pearson
                    sentiment_volume_correlations[f'{sent_col}_{vol_col}_spearman'] = corr_spearman
                    sentiment_volume_correlations[f'{sent_col}_{vol_col}_kendall'] = corr_kendall
        
        # === CORRÃ‰LATIONS TEMPORELLES ===
        print(f"   ğŸ”„ Calcul des corrÃ©lations temporelles...")
        
        # 4. CorrÃ©lations avec lag
        temporal_correlations = {}
        price_cols = ['close', 'volume']
        sentiment_cols = ['sentiment_score_normalized', 'sentiment_momentum_7d']
        
        for price_col in price_cols:
            for sent_col in sentiment_cols:
                if price_col in df.columns and sent_col in df.columns:
                    # Lag 1, 3, 7 jours
                    for lag in [1, 3, 7]:
                        if len(df) > lag:
                            # Prix vs Sentiment avec lag
                            corr_pearson, _ = pearsonr(df[price_col].iloc[lag:].dropna(), 
                                                     df[sent_col].iloc[:-lag].dropna())
                            corr_spearman, _ = spearmanr(df[price_col].iloc[lag:].dropna(), 
                                                       df[sent_col].iloc[:-lag].dropna())
                            
                            temporal_correlations[f'{price_col}_{sent_col}_lag{lag}_pearson'] = corr_pearson
                            temporal_correlations[f'{price_col}_{sent_col}_lag{lag}_spearman'] = corr_spearman
        
        # 5. CorrÃ©lations rolling
        rolling_correlations = {}
        window_sizes = [5, 10, 20]
        
        for window in window_sizes:
            if len(df) > window:
                # Rolling correlation entre prix et sentiment
                rolling_corr = df['close'].rolling(window=window).corr(df['sentiment_score_normalized'])
                rolling_correlations[f'rolling_corr_price_sentiment_{window}d'] = rolling_corr.mean()
                
                # Rolling correlation entre volume et sentiment
                rolling_corr_vol = df['volume'].rolling(window=window).corr(df['sentiment_score_normalized'])
                rolling_correlations[f'rolling_corr_volume_sentiment_{window}d'] = rolling_corr_vol.mean()
        
        # === CORRÃ‰LATIONS CROSS-ASSET ===
        print(f"   ğŸ”„ Calcul des corrÃ©lations cross-asset...")
        
        # 6. CorrÃ©lations avec le marchÃ© (approximation avec moyenne des autres symboles)
        cross_asset_correlations = {}
        
        # RÃ©cupÃ©rer les donnÃ©es moyennes du marchÃ©
        query_market = """
        SELECT date, AVG(close) as market_close, AVG(volume) as market_volume
        FROM historical_data 
        WHERE symbol != %s AND date IN (
            SELECT date FROM historical_data WHERE symbol = %s ORDER BY date DESC LIMIT %s
        )
        GROUP BY date
        ORDER BY date DESC
        LIMIT %s
        """
        
        df_market = pd.read_sql(query_market, conn, params=[symbol, symbol, limit_per_symbol, limit_per_symbol])
        
        if not df_market.empty:
            # Fusionner avec les donnÃ©es du marchÃ©
            df_with_market = df.merge(df_market, on='date', how='inner')
            
            if not df_with_market.empty:
                # CorrÃ©lation avec le marchÃ©
                corr_market_price, _ = pearsonr(df_with_market['close'].dropna(), 
                                              df_with_market['market_close'].dropna())
                corr_market_volume, _ = pearsonr(df_with_market['volume'].dropna(), 
                                               df_with_market['market_volume'].dropna())
                
                cross_asset_correlations['market_correlation_price'] = corr_market_price
                cross_asset_correlations['market_correlation_volume'] = corr_market_volume
        
        # === CORRÃ‰LATIONS MULTI-DIMENSIONNELLES ===
        print(f"   ğŸ”„ Calcul des corrÃ©lations multi-dimensionnelles...")
        
        # 7. CorrÃ©lations partielles (simplifiÃ©es)
        partial_correlations = {}
        
        # CorrÃ©lation partielle entre prix et sentiment, contrÃ´lant pour le volume
        if 'close' in df.columns and 'sentiment_score_normalized' in df.columns and 'volume' in df.columns:
            try:
                # Calculer la corrÃ©lation partielle simplifiÃ©e
                # CorrÃ©lation entre prix et sentiment, en contrÃ´lant pour le volume
                df_clean = df[['close', 'sentiment_score_normalized', 'volume']].dropna()
                if len(df_clean) > 10:
                    # Approximation de la corrÃ©lation partielle
                    corr_price_sent, _ = pearsonr(df_clean['close'], df_clean['sentiment_score_normalized'])
                    corr_price_vol, _ = pearsonr(df_clean['close'], df_clean['volume'])
                    corr_sent_vol, _ = pearsonr(df_clean['sentiment_score_normalized'], df_clean['volume'])
                    
                    # Formule de corrÃ©lation partielle
                    partial_corr_val = (corr_price_sent - corr_price_vol * corr_sent_vol) / \
                                     np.sqrt((1 - corr_price_vol**2) * (1 - corr_sent_vol**2))
                    partial_correlations['partial_corr_price_sentiment_volume'] = partial_corr_val
                else:
                    partial_correlations['partial_corr_price_sentiment_volume'] = None
            except:
                partial_correlations['partial_corr_price_sentiment_volume'] = None
        
        # 8. CorrÃ©lations composites
        composite_correlations = {}
        
        # Score composite technique
        if 'rsi_14' in df.columns and 'macd' in df.columns and 'stochastic_k' in df.columns:
            technical_score = (df['rsi_14'] + df['macd'] + df['stochastic_k']) / 3
            corr_tech_price, _ = pearsonr(technical_score.dropna(), df['close'].dropna())
            composite_correlations['technical_score_price_correlation'] = corr_tech_price
        
        # Score composite sentiment
        if 'sentiment_score_normalized' in df.columns and 'news_positive_ratio' in df.columns:
            sentiment_score = (df['sentiment_score_normalized'] + df['news_positive_ratio'] * 100) / 2
            corr_sent_price, _ = pearsonr(sentiment_score.dropna(), df['close'].dropna())
            composite_correlations['sentiment_score_price_correlation'] = corr_sent_price
        
        # === PRÃ‰PARATION DES DONNÃ‰ES POUR L'INSERTION ===
        print(f"   ğŸ”„ PrÃ©paration des donnÃ©es pour l'insertion...")
        
        # Combiner toutes les corrÃ©lations
        all_correlations = {
            **price_volume_correlations,
            **technical_sentiment_correlations,
            **sentiment_volume_correlations,
            **temporal_correlations,
            **rolling_correlations,
            **cross_asset_correlations,
            **partial_correlations,
            **composite_correlations
        }
        
        # PrÃ©parer les donnÃ©es pour l'insertion
        data_to_insert = []
        for date_val in df['date'].unique():
            correlation_data = {
                'symbol': symbol,
                'date': date_val,
                **all_correlations
            }
            data_to_insert.append(correlation_data)
        
        # InsÃ©rer les donnÃ©es avec lock pour Ã©viter les conflits
        with db_lock:
            # CrÃ©er la table si elle n'existe pas
            create_table_query = """
            CREATE TABLE IF NOT EXISTS correlation_analysis (
                id SERIAL PRIMARY KEY,
                symbol VARCHAR(10) NOT NULL,
                date DATE NOT NULL,
                -- CorrÃ©lations Prix-Volume
                open_volume_pearson DECIMAL(10, 6),
                open_volume_spearman DECIMAL(10, 6),
                open_volume_kendall DECIMAL(10, 6),
                close_volume_pearson DECIMAL(10, 6),
                close_volume_spearman DECIMAL(10, 6),
                close_volume_kendall DECIMAL(10, 6),
                close_obv_pearson DECIMAL(10, 6),
                close_obv_spearman DECIMAL(10, 6),
                close_obv_kendall DECIMAL(10, 6),
                -- CorrÃ©lations Technique-Sentiment
                rsi_14_sentiment_score_normalized_pearson DECIMAL(10, 6),
                rsi_14_sentiment_score_normalized_spearman DECIMAL(10, 6),
                rsi_14_sentiment_score_normalized_kendall DECIMAL(10, 6),
                macd_sentiment_score_normalized_pearson DECIMAL(10, 6),
                macd_sentiment_score_normalized_spearman DECIMAL(10, 6),
                macd_sentiment_score_normalized_kendall DECIMAL(10, 6),
                -- CorrÃ©lations Sentiment-Volume
                sentiment_score_normalized_volume_pearson DECIMAL(10, 6),
                sentiment_score_normalized_volume_spearman DECIMAL(10, 6),
                sentiment_score_normalized_volume_kendall DECIMAL(10, 6),
                -- CorrÃ©lations Temporelles
                close_sentiment_score_normalized_lag1_pearson DECIMAL(10, 6),
                close_sentiment_score_normalized_lag1_spearman DECIMAL(10, 6),
                close_sentiment_score_normalized_lag3_pearson DECIMAL(10, 6),
                close_sentiment_score_normalized_lag3_spearman DECIMAL(10, 6),
                close_sentiment_score_normalized_lag7_pearson DECIMAL(10, 6),
                close_sentiment_score_normalized_lag7_spearman DECIMAL(10, 6),
                -- CorrÃ©lations Rolling
                rolling_corr_price_sentiment_5d DECIMAL(10, 6),
                rolling_corr_price_sentiment_10d DECIMAL(10, 6),
                rolling_corr_price_sentiment_20d DECIMAL(10, 6),
                rolling_corr_volume_sentiment_5d DECIMAL(10, 6),
                rolling_corr_volume_sentiment_10d DECIMAL(10, 6),
                rolling_corr_volume_sentiment_20d DECIMAL(10, 6),
                -- CorrÃ©lations Cross-Asset
                market_correlation_price DECIMAL(10, 6),
                market_correlation_volume DECIMAL(10, 6),
                -- CorrÃ©lations Partielles
                partial_corr_price_sentiment_volume DECIMAL(10, 6),
                -- CorrÃ©lations Composites
                technical_score_price_correlation DECIMAL(10, 6),
                sentiment_score_price_correlation DECIMAL(10, 6),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(symbol, date)
            )
            """
            
            cursor = conn.cursor()
            cursor.execute(create_table_query)
            conn.commit()
            
            # InsÃ©rer les donnÃ©es
            if data_to_insert:
                insert_query = """
                INSERT INTO correlation_analysis 
                (symbol, date, open_volume_pearson, open_volume_spearman, open_volume_kendall,
                 close_volume_pearson, close_volume_spearman, close_volume_kendall,
                 close_obv_pearson, close_obv_spearman, close_obv_kendall,
                 rsi_14_sentiment_score_normalized_pearson, rsi_14_sentiment_score_normalized_spearman, rsi_14_sentiment_score_normalized_kendall,
                 macd_sentiment_score_normalized_pearson, macd_sentiment_score_normalized_spearman, macd_sentiment_score_normalized_kendall,
                 sentiment_score_normalized_volume_pearson, sentiment_score_normalized_volume_spearman, sentiment_score_normalized_volume_kendall,
                 close_sentiment_score_normalized_lag1_pearson, close_sentiment_score_normalized_lag1_spearman,
                 close_sentiment_score_normalized_lag3_pearson, close_sentiment_score_normalized_lag3_spearman,
                 close_sentiment_score_normalized_lag7_pearson, close_sentiment_score_normalized_lag7_spearman,
                 rolling_corr_price_sentiment_5d, rolling_corr_price_sentiment_10d, rolling_corr_price_sentiment_20d,
                 rolling_corr_volume_sentiment_5d, rolling_corr_volume_sentiment_10d, rolling_corr_volume_sentiment_20d,
                 market_correlation_price, market_correlation_volume,
                 partial_corr_price_sentiment_volume, technical_score_price_correlation, sentiment_score_price_correlation)
                VALUES %s
                ON CONFLICT (symbol, date) DO UPDATE SET
                    open_volume_pearson = EXCLUDED.open_volume_pearson,
                    open_volume_spearman = EXCLUDED.open_volume_spearman,
                    open_volume_kendall = EXCLUDED.open_volume_kendall,
                    close_volume_pearson = EXCLUDED.close_volume_pearson,
                    close_volume_spearman = EXCLUDED.close_volume_spearman,
                    close_volume_kendall = EXCLUDED.close_volume_kendall,
                    close_obv_pearson = EXCLUDED.close_obv_pearson,
                    close_obv_spearman = EXCLUDED.close_obv_spearman,
                    close_obv_kendall = EXCLUDED.close_obv_kendall,
                    rsi_14_sentiment_score_normalized_pearson = EXCLUDED.rsi_14_sentiment_score_normalized_pearson,
                    rsi_14_sentiment_score_normalized_spearman = EXCLUDED.rsi_14_sentiment_score_normalized_spearman,
                    rsi_14_sentiment_score_normalized_kendall = EXCLUDED.rsi_14_sentiment_score_normalized_kendall,
                    macd_sentiment_score_normalized_pearson = EXCLUDED.macd_sentiment_score_normalized_pearson,
                    macd_sentiment_score_normalized_spearman = EXCLUDED.macd_sentiment_score_normalized_spearman,
                    macd_sentiment_score_normalized_kendall = EXCLUDED.macd_sentiment_score_normalized_kendall,
                    sentiment_score_normalized_volume_pearson = EXCLUDED.sentiment_score_normalized_volume_pearson,
                    sentiment_score_normalized_volume_spearman = EXCLUDED.sentiment_score_normalized_volume_spearman,
                    sentiment_score_normalized_volume_kendall = EXCLUDED.sentiment_score_normalized_volume_kendall,
                    close_sentiment_score_normalized_lag1_pearson = EXCLUDED.close_sentiment_score_normalized_lag1_pearson,
                    close_sentiment_score_normalized_lag1_spearman = EXCLUDED.close_sentiment_score_normalized_lag1_spearman,
                    close_sentiment_score_normalized_lag3_pearson = EXCLUDED.close_sentiment_score_normalized_lag3_pearson,
                    close_sentiment_score_normalized_lag3_spearman = EXCLUDED.close_sentiment_score_normalized_lag3_spearman,
                    close_sentiment_score_normalized_lag7_pearson = EXCLUDED.close_sentiment_score_normalized_lag7_pearson,
                    close_sentiment_score_normalized_lag7_spearman = EXCLUDED.close_sentiment_score_normalized_lag7_spearman,
                    rolling_corr_price_sentiment_5d = EXCLUDED.rolling_corr_price_sentiment_5d,
                    rolling_corr_price_sentiment_10d = EXCLUDED.rolling_corr_price_sentiment_10d,
                    rolling_corr_price_sentiment_20d = EXCLUDED.rolling_corr_price_sentiment_20d,
                    rolling_corr_volume_sentiment_5d = EXCLUDED.rolling_corr_volume_sentiment_5d,
                    rolling_corr_volume_sentiment_10d = EXCLUDED.rolling_corr_volume_sentiment_10d,
                    rolling_corr_volume_sentiment_20d = EXCLUDED.rolling_corr_volume_sentiment_20d,
                    market_correlation_price = EXCLUDED.market_correlation_price,
                    market_correlation_volume = EXCLUDED.market_correlation_volume,
                    partial_corr_price_sentiment_volume = EXCLUDED.partial_corr_price_sentiment_volume,
                    technical_score_price_correlation = EXCLUDED.technical_score_price_correlation,
                    sentiment_score_price_correlation = EXCLUDED.sentiment_score_price_correlation
                """
                
                # PrÃ©parer les donnÃ©es pour l'insertion
                insert_data = []
                for data in data_to_insert:
                    insert_data.append((
                        data['symbol'],
                        data['date'],
                        data.get('open_volume_pearson'),
                        data.get('open_volume_spearman'),
                        data.get('open_volume_kendall'),
                        data.get('close_volume_pearson'),
                        data.get('close_volume_spearman'),
                        data.get('close_volume_kendall'),
                        data.get('close_obv_pearson'),
                        data.get('close_obv_spearman'),
                        data.get('close_obv_kendall'),
                        data.get('rsi_14_sentiment_score_normalized_pearson'),
                        data.get('rsi_14_sentiment_score_normalized_spearman'),
                        data.get('rsi_14_sentiment_score_normalized_kendall'),
                        data.get('macd_sentiment_score_normalized_pearson'),
                        data.get('macd_sentiment_score_normalized_spearman'),
                        data.get('macd_sentiment_score_normalized_kendall'),
                        data.get('sentiment_score_normalized_volume_pearson'),
                        data.get('sentiment_score_normalized_volume_spearman'),
                        data.get('sentiment_score_normalized_volume_kendall'),
                        data.get('close_sentiment_score_normalized_lag1_pearson'),
                        data.get('close_sentiment_score_normalized_lag1_spearman'),
                        data.get('close_sentiment_score_normalized_lag3_pearson'),
                        data.get('close_sentiment_score_normalized_lag3_spearman'),
                        data.get('close_sentiment_score_normalized_lag7_pearson'),
                        data.get('close_sentiment_score_normalized_lag7_spearman'),
                        data.get('rolling_corr_price_sentiment_5d'),
                        data.get('rolling_corr_price_sentiment_10d'),
                        data.get('rolling_corr_price_sentiment_20d'),
                        data.get('rolling_corr_volume_sentiment_5d'),
                        data.get('rolling_corr_volume_sentiment_10d'),
                        data.get('rolling_corr_volume_sentiment_20d'),
                        data.get('market_correlation_price'),
                        data.get('market_correlation_volume'),
                        data.get('partial_corr_price_sentiment_volume'),
                        data.get('technical_score_price_correlation'),
                        data.get('sentiment_score_price_correlation')
                    ))
                
                execute_values(cursor, insert_query, insert_data)
                conn.commit()
        
        return symbol, len(data_to_insert), "SuccÃ¨s"
        
    except Exception as e:
        return symbol, 0, f"Erreur: {e}"
    
    finally:
        conn.close()

def process_correlation_symbols_batch(symbols: list, batch_size: int = 5):
    """Traiter les symboles par batch avec parallÃ©lisation"""
    
    total_processed = 0
    total_errors = 0
    results = []
    
    print(f"ğŸ”„ Traitement de {len(symbols)} symboles par batch de {batch_size}...")
    
    # Traiter par batch
    for i in range(0, len(symbols), batch_size):
        batch = symbols[i:i + batch_size]
        batch_num = (i // batch_size) + 1
        total_batches = (len(symbols) + batch_size - 1) // batch_size
        
        print(f"\nğŸ“Š Batch {batch_num}/{total_batches}: {', '.join(batch)}")
        
        # Traitement parallÃ¨le du batch
        with ThreadPoolExecutor(max_workers=batch_size) as executor:
            future_to_symbol = {
                executor.submit(calculate_correlations_for_symbol, symbol): symbol 
                for symbol in batch
            }
            
            for future in as_completed(future_to_symbol):
                symbol = future_to_symbol[future]
                try:
                    result_symbol, count, status = future.result()
                    results.append((result_symbol, count, status))
                    
                    if count > 0:
                        print(f"   âœ… {result_symbol}: {count} corrÃ©lations calculÃ©es")
                        total_processed += count
                    else:
                        print(f"   âŒ {result_symbol}: {status}")
                        total_errors += 1
                        
                except Exception as e:
                    print(f"   âŒ {symbol}: Erreur inattendue: {e}")
                    total_errors += 1
    
    return results, total_processed, total_errors

def main():
    """Fonction principale"""
    print("ğŸš€ DÃ©marrage du calcul des corrÃ©lations...")
    
    # RÃ©cupÃ©rer tous les symboles
    symbols = get_all_symbols()
    if not symbols:
        print("âŒ Aucun symbole trouvÃ©")
        return
    
    print(f"ğŸ“ˆ {len(symbols)} symboles Ã  traiter")
    
    start_time = time.time()
    
    # Traiter par batch
    results, total_processed, total_errors = process_correlation_symbols_batch(symbols, batch_size=3)
    
    end_time = time.time()
    
    # RÃ©sumÃ© final
    print(f"\nğŸ“Š RÃ©sumÃ© final:")
    print(f"   Symboles traitÃ©s: {len(symbols)}")
    print(f"   CorrÃ©lations calculÃ©es: {total_processed}")
    print(f"   Erreurs: {total_errors}")
    print(f"   Temps total: {end_time - start_time:.2f} secondes")
    print(f"   Temps moyen par symbole: {(end_time - start_time) / len(symbols):.2f} secondes")
    
    # Statistiques par symbole
    print(f"\nğŸ“ˆ Statistiques par symbole:")
    for symbol, count, status in results:
        if count > 0:
            print(f"   âœ… {symbol}: {count} corrÃ©lations")
        else:
            print(f"   âŒ {symbol}: {status}")

if __name__ == "__main__":
    main()
