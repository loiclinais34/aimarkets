import pandas as pd
import numpy as np
from sqlalchemy.orm import Session
from sqlalchemy import text
from typing import List, Dict, Optional, Tuple
from datetime import datetime, timedelta, date
import joblib
import os
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import warnings
warnings.filterwarnings('ignore')
import shap

from app.models.database import (
    HistoricalData, TechnicalIndicators, SentimentIndicators, 
    TargetParameters, MLModels, MLPredictions
)
from app.core.config import settings


class MLService:
    def __init__(self, db: Session = None):
        if db is None:
            from app.core.database import SessionLocal
            self.db = SessionLocal()
            self.should_close_db = True
        else:
            self.db = db
            self.should_close_db = False
        
        # Correction du chemin des mod√®les - utiliser un chemin absolu
        self.models_path = os.path.abspath(settings.ml_models_path)
        print(f"üîß [ML_SERVICE] Chemin des mod√®les: {self.models_path}")
        os.makedirs(self.models_path, exist_ok=True)
        print(f"üîß [ML_SERVICE] R√©pertoire des mod√®les cr√©√©/v√©rifi√©: {self.models_path}")
    
    def close(self):
        """Fermer la session DB si elle a √©t√© cr√©√©e par le service"""
        if self.should_close_db and self.db:
            self.db.close()
    
    def create_target_parameter(self, user_id: str, parameter_name: str, 
                              target_return_percentage: float, time_horizon_days: int,
                              risk_tolerance: str = 'medium', min_confidence_threshold: float = 0.7,
                              max_drawdown_percentage: float = 5.0, db: Session = None) -> TargetParameters:
        """Cr√©er un nouveau param√®tre de cible de rentabilit√©"""
        print(f"üîß [CREATE_TARGET] Cr√©ation param√®tre pour {user_id}")
        
        # Utiliser la session pass√©e en param√®tre ou celle de l'instance
        session = db or self.db
        if session is None:
            from app.core.database import SessionLocal
            session = SessionLocal()
            should_close_session = True
            print(f"üîß [CREATE_TARGET] Session DB cr√©√©e: {type(session)}")
        else:
            should_close_session = False
            print(f"üîß [CREATE_TARGET] Session DB utilis√©e: {type(session)}")
        
        try:
            target_param = TargetParameters(
                user_id=user_id,
                parameter_name=parameter_name,
                target_return_percentage=target_return_percentage,
                time_horizon_days=time_horizon_days,
                risk_tolerance=risk_tolerance,
                min_confidence_threshold=min_confidence_threshold,
                max_drawdown_percentage=max_drawdown_percentage
            )
            session.add(target_param)
            session.commit()
            session.refresh(target_param)
            print(f"üîß [CREATE_TARGET] Param√®tre cr√©√© avec ID: {target_param.id}")
            return target_param
        finally:
            if should_close_session:
                session.close()
    
    def get_target_parameters(self, user_id: str, db: Session = None) -> List[TargetParameters]:
        """R√©cup√©rer les param√®tres de cible pour un utilisateur"""
        # Utiliser la session pass√©e en param√®tre ou celle de l'instance
        session = db or self.db
        if session is None:
            from app.core.database import SessionLocal
            session = SessionLocal()
            should_close_session = True
        else:
            should_close_session = False
        
        try:
            return session.query(TargetParameters).filter(
                TargetParameters.user_id == user_id,
                TargetParameters.is_active == True
            ).all()
        finally:
            if should_close_session:
                session.close()
    
    def calculate_target_price(self, current_price: float, target_return_percentage: float, 
                             time_horizon_days: int) -> float:
        """Calculer le prix cible bas√© sur le rendement attendu"""
        # Convertir en float pour √©viter les probl√®mes de type
        current_price = float(current_price)
        target_return_percentage = float(target_return_percentage)
        time_horizon_days = int(time_horizon_days)
        
        # Calcul du rendement quotidien √©quivalent
        daily_return = (1 + target_return_percentage / 100) ** (1 / time_horizon_days) - 1
        # Calcul du prix cible
        target_price = current_price * (1 + daily_return * time_horizon_days)
        return target_price
    
    def create_labels_for_training(self, symbol: str, target_param: TargetParameters, db: Session = None) -> pd.DataFrame:
        """Cr√©er les labels pour l'entra√Ænement bas√©s sur les param√®tres de cible"""
        # Utiliser la session pass√©e en param√®tre ou celle de l'instance
        session = db or self.db
        
        # R√©cup√©rer les donn√©es historiques avec SQLAlchemy ORM
        historical_data = session.query(HistoricalData).filter(
            HistoricalData.symbol == symbol
        ).order_by(HistoricalData.date).all()
        
        if not historical_data:
            return pd.DataFrame()
        
        # Convertir en DataFrame
        data = []
        for h in historical_data:
            # R√©cup√©rer les indicateurs techniques
            tech = session.query(TechnicalIndicators).filter(
                TechnicalIndicators.symbol == symbol,
                TechnicalIndicators.date == h.date
            ).first()
            
            # R√©cup√©rer les indicateurs de sentiment
            sent = session.query(SentimentIndicators).filter(
                SentimentIndicators.symbol == symbol,
                SentimentIndicators.date == h.date
            ).first()
            
            # Pr√©parer les donn√©es de base
            row_data = {
                'date': h.date,
                'close': float(h.close),
                'volume': h.volume,
                'vwap': float(h.vwap) if h.vwap else None,
            }
            
            # Ajouter tous les indicateurs techniques disponibles
            if tech:
                tech_indicators = {
                    # Moyennes mobiles
                    'sma_5': float(tech.sma_5) if tech.sma_5 else None,
                    'sma_10': float(tech.sma_10) if tech.sma_10 else None,
                    'sma_20': float(tech.sma_20) if tech.sma_20 else None,
                    'sma_50': float(tech.sma_50) if tech.sma_50 else None,
                    'sma_200': float(tech.sma_200) if tech.sma_200 else None,
                    'ema_5': float(tech.ema_5) if tech.ema_5 else None,
                    'ema_10': float(tech.ema_10) if tech.ema_10 else None,
                    'ema_20': float(tech.ema_20) if tech.ema_20 else None,
                    'ema_50': float(tech.ema_50) if tech.ema_50 else None,
                    'ema_200': float(tech.ema_200) if tech.ema_200 else None,
                    
                    # Indicateurs de momentum
                    'rsi_14': float(tech.rsi_14) if tech.rsi_14 else None,
                    'macd': float(tech.macd) if tech.macd else None,
                    'macd_signal': float(tech.macd_signal) if tech.macd_signal else None,
                    'macd_histogram': float(tech.macd_histogram) if tech.macd_histogram else None,
                    'stochastic_k': float(tech.stochastic_k) if tech.stochastic_k else None,
                    'stochastic_d': float(tech.stochastic_d) if tech.stochastic_d else None,
                    'williams_r': float(tech.williams_r) if tech.williams_r else None,
                    'roc': float(tech.roc) if tech.roc else None,
                    'cci': float(tech.cci) if tech.cci else None,
                    
                    # Bollinger Bands
                    'bb_middle': float(tech.bb_middle) if tech.bb_middle else None,
                    'bb_lower': float(tech.bb_lower) if tech.bb_lower else None,
                    'bb_width': float(tech.bb_width) if tech.bb_width else None,
                    'bb_position': float(tech.bb_position) if tech.bb_position else None,
                    
                    # Volume
                    'obv': float(tech.obv) if tech.obv else None,
                    'volume_roc': float(tech.volume_roc) if tech.volume_roc else None,
                    'volume_sma_20': float(tech.volume_sma_20) if tech.volume_sma_20 else None,
                    
                    # ATR
                    'atr_14': float(tech.atr_14) if tech.atr_14 else None,
                }
                row_data.update(tech_indicators)
            
            # Ajouter tous les indicateurs de sentiment disponibles
            if sent:
                sent_indicators = {
                    # Base Sentiment Indicators
                    'sentiment_score_normalized': float(sent.sentiment_score_normalized) if sent.sentiment_score_normalized else None,
                    
                    # Sentiment Momentum
                    'sentiment_momentum_1d': float(sent.sentiment_momentum_1d) if sent.sentiment_momentum_1d else None,
                    'sentiment_momentum_3d': float(sent.sentiment_momentum_3d) if sent.sentiment_momentum_3d else None,
                    'sentiment_momentum_7d': float(sent.sentiment_momentum_7d) if sent.sentiment_momentum_7d else None,
                    'sentiment_momentum_14d': float(sent.sentiment_momentum_14d) if sent.sentiment_momentum_14d else None,
                    
                    # Sentiment Volatility
                    'sentiment_volatility_3d': float(sent.sentiment_volatility_3d) if sent.sentiment_volatility_3d else None,
                    'sentiment_volatility_7d': float(sent.sentiment_volatility_7d) if sent.sentiment_volatility_7d else None,
                    'sentiment_volatility_14d': float(sent.sentiment_volatility_14d) if sent.sentiment_volatility_14d else None,
                    'sentiment_volatility_30d': float(sent.sentiment_volatility_30d) if sent.sentiment_volatility_30d else None,
                    
                    # Sentiment Moving Averages
                    'sentiment_sma_3': float(sent.sentiment_sma_3) if sent.sentiment_sma_3 else None,
                    'sentiment_sma_7': float(sent.sentiment_sma_7) if sent.sentiment_sma_7 else None,
                    'sentiment_sma_14': float(sent.sentiment_sma_14) if sent.sentiment_sma_14 else None,
                    'sentiment_sma_30': float(sent.sentiment_sma_30) if sent.sentiment_sma_30 else None,
                    'sentiment_ema_3': float(sent.sentiment_ema_3) if sent.sentiment_ema_3 else None,
                    'sentiment_ema_7': float(sent.sentiment_ema_7) if sent.sentiment_ema_7 else None,
                    'sentiment_ema_14': float(sent.sentiment_ema_14) if sent.sentiment_ema_14 else None,
                    'sentiment_ema_30': float(sent.sentiment_ema_30) if sent.sentiment_ema_30 else None,
                    
                    # Sentiment Oscillators
                    'sentiment_rsi_14': float(sent.sentiment_rsi_14) if sent.sentiment_rsi_14 else None,
                    'sentiment_macd': float(sent.sentiment_macd) if sent.sentiment_macd else None,
                    'sentiment_macd_signal': float(sent.sentiment_macd_signal) if sent.sentiment_macd_signal else None,
                    'sentiment_macd_histogram': float(sent.sentiment_macd_histogram) if sent.sentiment_macd_histogram else None,
                    
                    # News Volume Indicators
                    'news_volume_sma_7': float(sent.news_volume_sma_7) if sent.news_volume_sma_7 else None,
                    'news_volume_sma_14': float(sent.news_volume_sma_14) if sent.news_volume_sma_14 else None,
                    'news_volume_sma_30': float(sent.news_volume_sma_30) if sent.news_volume_sma_30 else None,
                    'news_volume_roc_7d': float(sent.news_volume_roc_7d) if sent.news_volume_roc_7d else None,
                    'news_volume_roc_14d': float(sent.news_volume_roc_14d) if sent.news_volume_roc_14d else None,
                    
                    # Sentiment Distribution Ratios
                    'news_positive_ratio': float(sent.news_positive_ratio) if sent.news_positive_ratio else None,
                    'news_negative_ratio': float(sent.news_negative_ratio) if sent.news_negative_ratio else None,
                    'news_neutral_ratio': float(sent.news_neutral_ratio) if sent.news_neutral_ratio else None,
                    'news_sentiment_quality': float(sent.news_sentiment_quality) if sent.news_sentiment_quality else None,
                    
                    # Short Interest Indicators
                    'short_interest_momentum_5d': float(sent.short_interest_momentum_5d) if sent.short_interest_momentum_5d else None,
                    'short_interest_momentum_10d': float(sent.short_interest_momentum_10d) if sent.short_interest_momentum_10d else None,
                    'short_interest_momentum_20d': float(sent.short_interest_momentum_20d) if sent.short_interest_momentum_20d else None,
                    'short_interest_volatility_7d': float(sent.short_interest_volatility_7d) if sent.short_interest_volatility_7d else None,
                    'short_interest_volatility_14d': float(sent.short_interest_volatility_14d) if sent.short_interest_volatility_14d else None,
                    'short_interest_volatility_30d': float(sent.short_interest_volatility_30d) if sent.short_interest_volatility_30d else None,
                    'short_interest_sma_7': float(sent.short_interest_sma_7) if sent.short_interest_sma_7 else None,
                    'short_interest_sma_14': float(sent.short_interest_sma_14) if sent.short_interest_sma_14 else None,
                    'short_interest_sma_30': float(sent.short_interest_sma_30) if sent.short_interest_sma_30 else None,
                    
                    # Short Volume Indicators
                    'short_volume_momentum_5d': float(sent.short_volume_momentum_5d) if sent.short_volume_momentum_5d else None,
                    'short_volume_momentum_10d': float(sent.short_volume_momentum_10d) if sent.short_volume_momentum_10d else None,
                    'short_volume_momentum_20d': float(sent.short_volume_momentum_20d) if sent.short_volume_momentum_20d else None,
                    'short_volume_volatility_7d': float(sent.short_volume_volatility_7d) if sent.short_volume_volatility_7d else None,
                    'short_volume_volatility_14d': float(sent.short_volume_volatility_14d) if sent.short_volume_volatility_14d else None,
                    'short_volume_volatility_30d': float(sent.short_volume_volatility_30d) if sent.short_volume_volatility_30d else None,
                    
                    # Composite Sentiment Indicators
                    'sentiment_strength_index': float(sent.sentiment_strength_index) if sent.sentiment_strength_index else None,
                    'market_sentiment_index': float(sent.market_sentiment_index) if sent.market_sentiment_index else None,
                    'sentiment_divergence': float(sent.sentiment_divergence) if sent.sentiment_divergence else None,
                    'sentiment_acceleration': float(sent.sentiment_acceleration) if sent.sentiment_acceleration else None,
                    'sentiment_trend_strength': float(sent.sentiment_trend_strength) if sent.sentiment_trend_strength else None,
                    'sentiment_quality_index': float(sent.sentiment_quality_index) if sent.sentiment_quality_index else None,
                    'sentiment_risk_score': float(sent.sentiment_risk_score) if sent.sentiment_risk_score else None,
                }
                row_data.update(sent_indicators)
            
            data.append(row_data)
        
        df = pd.DataFrame(data)
        
        if df.empty:
            return pd.DataFrame()
        
        # Calculer le prix cible pour chaque jour
        df['target_price'] = df['close'].apply(
            lambda x: self.calculate_target_price(x, target_param.target_return_percentage, target_param.time_horizon_days)
        )
        
        # Calculer le rendement r√©el sur l'horizon
        df['future_close'] = df['close'].shift(-target_param.time_horizon_days)
        df['actual_return'] = (df['future_close'] - df['close']) / df['close'] * 100
        
        # Cr√©er les labels de classification
        target_return_float = float(target_param.target_return_percentage)
        df['target_achieved'] = (df['actual_return'] >= target_return_float).astype(int)
        
        # Cr√©er les labels de r√©gression (rendement r√©el)
        df['target_return'] = df['actual_return']
        
        # Remplacer les valeurs NaN par des valeurs par d√©faut au lieu de supprimer les lignes
        # Pour les features num√©riques, utiliser la m√©diane ou 0
        numeric_columns = [
            # Donn√©es de base
            'close', 'volume', 'vwap',
            
            # Moyennes mobiles techniques
            'sma_5', 'sma_10', 'sma_20', 'sma_50', 'sma_200',
            'ema_5', 'ema_10', 'ema_20', 'ema_50', 'ema_200',
            
            # Indicateurs de momentum techniques
            'rsi_14', 'macd', 'macd_signal', 'macd_histogram',
            'stochastic_k', 'stochastic_d', 'williams_r', 'roc', 'cci',
            
            # Bollinger Bands
            'bb_middle', 'bb_lower', 'bb_width', 'bb_position',
            
            # Volume techniques
            'obv', 'volume_roc', 'volume_sma_20',
            
            # ATR
            'atr_14',
            
            # Indicateurs de sentiment de base
            'sentiment_score_normalized',
            
            # Sentiment Momentum
            'sentiment_momentum_1d', 'sentiment_momentum_3d', 'sentiment_momentum_7d', 'sentiment_momentum_14d',
            
            # Sentiment Volatility
            'sentiment_volatility_3d', 'sentiment_volatility_7d', 'sentiment_volatility_14d', 'sentiment_volatility_30d',
            
            # Sentiment Moving Averages
            'sentiment_sma_3', 'sentiment_sma_7', 'sentiment_sma_14', 'sentiment_sma_30',
            'sentiment_ema_3', 'sentiment_ema_7', 'sentiment_ema_14', 'sentiment_ema_30',
            
            # Sentiment Oscillators
            'sentiment_rsi_14', 'sentiment_macd', 'sentiment_macd_signal', 'sentiment_macd_histogram',
            
            # News Volume Indicators
            'news_volume_sma_7', 'news_volume_sma_14', 'news_volume_sma_30',
            'news_volume_roc_7d', 'news_volume_roc_14d',
            
            # Sentiment Distribution Ratios
            'news_positive_ratio', 'news_negative_ratio', 'news_neutral_ratio', 'news_sentiment_quality',
            
            # Short Interest Indicators
            'short_interest_momentum_5d', 'short_interest_momentum_10d', 'short_interest_momentum_20d',
            'short_interest_volatility_7d', 'short_interest_volatility_14d', 'short_interest_volatility_30d',
            'short_interest_sma_7', 'short_interest_sma_14', 'short_interest_sma_30',
            
            # Short Volume Indicators
            'short_volume_momentum_5d', 'short_volume_momentum_10d', 'short_volume_momentum_20d',
            'short_volume_volatility_7d', 'short_volume_volatility_14d', 'short_volume_volatility_30d',
            
            # Composite Sentiment Indicators
            'sentiment_strength_index', 'market_sentiment_index', 'sentiment_divergence',
            'sentiment_acceleration', 'sentiment_trend_strength', 'sentiment_quality_index', 'sentiment_risk_score'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                # Remplacer NaN par la m√©diane de la colonne, ou 0 si pas de donn√©es
                median_val = df[col].median() if not df[col].isna().all() else 0
                df[col] = df[col].fillna(median_val)
        
        # Supprimer seulement les lignes avec des valeurs manquantes critiques
        critical_columns = ['close', 'volume', 'target_price', 'future_close', 'actual_return']
        df = df.dropna(subset=critical_columns)
        
        return df
    
    def prepare_features(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, List[str]]:
        """Pr√©parer les features pour l'entra√Ænement avec toutes les dimensions enrichies"""
        
        # D√©finir toutes les features disponibles (toutes les colonnes sauf les colonnes de contr√¥le)
        exclude_columns = ['date', 'target_price', 'future_close', 'actual_return', 'target_achieved', 'target_return']
        feature_columns = [col for col in df.columns if col not in exclude_columns]
        
        # S√©lectionner les features disponibles
        available_features = [col for col in feature_columns if col in df.columns]
        
        # Cr√©er des features suppl√©mentaires
        df_features = df[available_features].copy()
        
        # Features de momentum suppl√©mentaires (si pas d√©j√† pr√©sentes)
        if 'close' in df.columns:
            if 'price_momentum_5d' not in df_features.columns:
                df_features['price_momentum_5d'] = df['close'].pct_change(5)
            if 'price_momentum_10d' not in df_features.columns:
                df_features['price_momentum_10d'] = df['close'].pct_change(10)
            if 'price_momentum_20d' not in df_features.columns:
                df_features['price_momentum_20d'] = df['close'].pct_change(20)
        
        if 'volume' in df.columns:
            if 'volume_momentum_5d' not in df_features.columns:
                df_features['volume_momentum_5d'] = df['volume'].pct_change(5)
            if 'volume_momentum_10d' not in df_features.columns:
                df_features['volume_momentum_10d'] = df['volume'].pct_change(10)
        
        # Features de volatilit√© suppl√©mentaires
        if 'close' in df.columns:
            if 'price_volatility_5d' not in df_features.columns:
                df_features['price_volatility_5d'] = df['close'].rolling(5).std()
            if 'price_volatility_10d' not in df_features.columns:
                df_features['price_volatility_10d'] = df['close'].rolling(10).std()
            if 'price_volatility_20d' not in df_features.columns:
                df_features['price_volatility_20d'] = df['close'].rolling(20).std()
        
        # Features de corr√©lation avanc√©es
        if 'close' in df.columns and 'sentiment_score_normalized' in df.columns:
            if 'price_sentiment_corr' not in df_features.columns:
                df_features['price_sentiment_corr'] = df['close'].rolling(20).corr(df['sentiment_score_normalized'])
        
        if 'volume' in df.columns and 'sentiment_score_normalized' in df.columns:
            if 'volume_sentiment_corr' not in df_features.columns:
                df_features['volume_sentiment_corr'] = df['volume'].rolling(20).corr(df['sentiment_score_normalized'])
        
        # Features de ratio avanc√©es
        if 'close' in df.columns and 'sma_20' in df.columns:
            if 'price_sma_ratio' not in df_features.columns:
                df_features['price_sma_ratio'] = df['close'] / df['sma_20']
        
        if 'close' in df.columns and 'ema_20' in df.columns:
            if 'price_ema_ratio' not in df_features.columns:
                df_features['price_ema_ratio'] = df['close'] / df['ema_20']
        
        # Features de divergence
        if 'rsi_14' in df.columns and 'sentiment_rsi_14' in df.columns:
            if 'rsi_sentiment_divergence' not in df_features.columns:
                df_features['rsi_sentiment_divergence'] = df['rsi_14'] - df['sentiment_rsi_14']
        
        # Features de momentum crois√©
        if 'sentiment_momentum_7d' in df.columns and 'sentiment_momentum_14d' in df.columns:
            if 'sentiment_momentum_acceleration' not in df_features.columns:
                df_features['sentiment_momentum_acceleration'] = df['sentiment_momentum_7d'] - df['sentiment_momentum_14d']
        
        # Remplacer les valeurs infinies et NaN
        df_features = df_features.replace([np.inf, -np.inf], np.nan)
        df_features = df_features.fillna(0)
        
        return df_features, df_features.columns.tolist()
    
    def prepare_features_for_prediction(self, df: pd.DataFrame, feature_names: List[str]) -> pd.DataFrame:
        """Pr√©parer les features pour la pr√©diction en utilisant exactement les m√™mes features que l'entra√Ænement"""
        
        # Cr√©er un DataFrame avec toutes les features n√©cessaires
        df_features = pd.DataFrame(index=df.index)
        
        # Ajouter toutes les features de base disponibles
        for feature in feature_names:
            if feature in df.columns:
                df_features[feature] = df[feature]
            else:
                # Si la feature n'existe pas, la cr√©er avec des valeurs par d√©faut
                if feature == 'price_momentum_5d' and 'close' in df.columns:
                    df_features[feature] = df['close'].pct_change(5)
                elif feature == 'price_momentum_10d' and 'close' in df.columns:
                    df_features[feature] = df['close'].pct_change(10)
                elif feature == 'price_momentum_20d' and 'close' in df.columns:
                    df_features[feature] = df['close'].pct_change(20)
                elif feature == 'volume_momentum_5d' and 'volume' in df.columns:
                    df_features[feature] = df['volume'].pct_change(5)
                elif feature == 'volume_momentum_10d' and 'volume' in df.columns:
                    df_features[feature] = df['volume'].pct_change(10)
                elif feature == 'price_volatility_5d' and 'close' in df.columns:
                    # Pour la pr√©diction, utiliser une valeur par d√©faut bas√©e sur l'historique r√©cent
                    # ou une estimation bas√©e sur la volatilit√© des autres features
                    if 'atr_14' in df.columns and not pd.isna(df['atr_14'].iloc[0]):
                        df_features[feature] = df['atr_14'] * 0.1  # Estimation bas√©e sur ATR
                    else:
                        df_features[feature] = df['close'].iloc[0] * 0.01  # 1% du prix comme estimation
                elif feature == 'price_volatility_10d' and 'close' in df.columns:
                    if 'atr_14' in df.columns and not pd.isna(df['atr_14'].iloc[0]):
                        df_features[feature] = df['atr_14'] * 0.15  # Estimation bas√©e sur ATR
                    else:
                        df_features[feature] = df['close'].iloc[0] * 0.015  # 1.5% du prix comme estimation
                elif feature == 'price_volatility_20d' and 'close' in df.columns:
                    if 'atr_14' in df.columns and not pd.isna(df['atr_14'].iloc[0]):
                        df_features[feature] = df['atr_14'] * 0.2  # Estimation bas√©e sur ATR
                    else:
                        df_features[feature] = df['close'].iloc[0] * 0.02  # 2% du prix comme estimation
                elif feature == 'price_sentiment_corr' and 'close' in df.columns and 'sentiment_score_normalized' in df.columns:
                    # Pour la corr√©lation, utiliser une valeur par d√©faut neutre
                    df_features[feature] = 0.0
                elif feature == 'volume_sentiment_corr' and 'volume' in df.columns and 'sentiment_score_normalized' in df.columns:
                    # Pour la corr√©lation, utiliser une valeur par d√©faut neutre
                    df_features[feature] = 0.0
                elif feature == 'price_sma_ratio' and 'close' in df.columns and 'sma_20' in df.columns:
                    df_features[feature] = df['close'] / df['sma_20']
                elif feature == 'price_ema_ratio' and 'close' in df.columns and 'ema_20' in df.columns:
                    df_features[feature] = df['close'] / df['ema_20']
                elif feature == 'rsi_sentiment_divergence' and 'rsi_14' in df.columns and 'sentiment_rsi_14' in df.columns:
                    df_features[feature] = df['rsi_14'] - df['sentiment_rsi_14']
                elif feature == 'sentiment_momentum_acceleration' and 'sentiment_momentum_7d' in df.columns and 'sentiment_momentum_14d' in df.columns:
                    df_features[feature] = df['sentiment_momentum_7d'] - df['sentiment_momentum_14d']
                else:
                    # Feature non reconnue, utiliser 0
                    df_features[feature] = 0
        
        # Remplacer les valeurs infinies et NaN
        df_features = df_features.replace([np.inf, -np.inf], np.nan)
        df_features = df_features.fillna(0)
        
        # S'assurer que l'ordre des colonnes correspond exactement √† feature_names
        df_features = df_features[feature_names]
        
        return df_features
    
    def train_classification_model(self, symbol: str, target_param: TargetParameters, db: Session = None) -> Dict:
        """Entra√Æner un mod√®le de classification pour pr√©dire si la cible sera atteinte"""
        print(f"üîß [TRAIN_CLASS] D√©but entra√Ænement classification pour {symbol}")
        print(f"üîß [TRAIN_CLASS] Target param: {target_param.id}, DB session: {type(db)}")
        
        # Utiliser la session pass√©e en param√®tre ou cr√©er une nouvelle session
        if db is None:
            from app.core.database import SessionLocal
            session = SessionLocal()
            should_close_session = True
            print(f"üîß [TRAIN_CLASS] Session DB cr√©√©e: {type(session)}")
        else:
            session = db
            should_close_session = False
            print(f"üîß [TRAIN_CLASS] Session DB utilis√©e: {type(session)}")
        
        # Cr√©er les donn√©es d'entra√Ænement
        df = self.create_labels_for_training(symbol, target_param, session)
        
        if df.empty or len(df) < 100:
            return {"error": "Pas assez de donn√©es pour l'entra√Ænement"}
        
        # Pr√©parer les features
        X, feature_names = self.prepare_features(df)
        y = df['target_achieved']
        
        # Diviser les donn√©es
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Normaliser les features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entra√Æner le mod√®le
        model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            random_state=42,
            class_weight='balanced'
        )
        model.fit(X_train_scaled, y_train)
        
        # √âvaluer le mod√®le
        y_pred = model.predict(X_test_scaled)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
        
        accuracy = accuracy_score(y_test, y_pred)
        precision = precision_score(y_test, y_pred, zero_division=0)
        recall = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        
        # Validation crois√©e
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='accuracy')
        
        # G√©n√©rer un nom de mod√®le unique
        base_name = f"classification_{symbol}_{target_param.parameter_name}"
        model_name = base_name
        
        # Trouver la prochaine version disponible
        version_num = 1
        while True:
            version = f"v{version_num}"
            existing = session.query(MLModels).filter(
                MLModels.model_name == model_name,
                MLModels.model_version == version
            ).first()
            if not existing:
                break
            version_num += 1
        
        # Cr√©er les chemins de fichiers avec la version
        model_path = os.path.join(self.models_path, f"{model_name}_{version}.joblib")
        scaler_path = os.path.join(self.models_path, f"{model_name}_{version}_scaler.joblib")
        
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        
        # Enregistrer le mod√®le en base
        ml_model = MLModels(
            model_name=model_name,
            model_type="classification",
            model_version=version,
            symbol=symbol,
            target_parameter_id=target_param.id,
            model_parameters={
                "target_return_percentage": float(target_param.target_return_percentage),
                "time_horizon_days": int(target_param.time_horizon_days),
                "risk_tolerance": str(target_param.risk_tolerance),
                "feature_names": feature_names,
                "training_data_start": str(df['date'].min()),
                "training_data_end": str(df['date'].max())
            },
            performance_metrics={
                "validation_score": float(cv_scores.mean()),
                "test_score": accuracy,
                "precision": precision,
                "recall": recall,
                "f1_score": f1,
                "cv_mean": float(cv_scores.mean()),
                "cv_std": float(cv_scores.std())
            },
            model_path=model_path,
            is_active=True,
            created_by="ml_service"
        )
        session.add(ml_model)
        session.commit()
        
        # Fermer la session si on l'a cr√©√©e
        if should_close_session:
            session.close()
        
        return {
            "success": True,
            "model_id": ml_model.id,
            "model_name": model_name,
            "accuracy": accuracy,
            "precision": precision,
            "recall": recall,
            "f1_score": f1,
            "cv_mean": float(cv_scores.mean()),
            "cv_std": float(cv_scores.std()),
            "feature_importance": dict(zip(feature_names, model.feature_importances_))
        }
    
    def train_regression_model(self, symbol: str, target_param: TargetParameters, db: Session = None) -> Dict:
        """Entra√Æner un mod√®le de r√©gression pour pr√©dire le rendement exact"""
        # Utiliser la session pass√©e en param√®tre ou cr√©er une nouvelle session
        if db is None:
            from app.core.database import SessionLocal
            session = SessionLocal()
            should_close_session = True
        else:
            session = db
            should_close_session = False
        
        # Cr√©er les donn√©es d'entra√Ænement
        df = self.create_labels_for_training(symbol, target_param, session)
        
        if df.empty or len(df) < 100:
            return {"error": "Pas assez de donn√©es pour l'entra√Ænement"}
        
        # Pr√©parer les features
        X, feature_names = self.prepare_features(df)
        y = df['target_return']
        
        # Diviser les donn√©es
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # Normaliser les features
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # Entra√Æner le mod√®le
        model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            random_state=42
        )
        model.fit(X_train_scaled, y_train)
        
        # √âvaluer le mod√®le
        y_pred = model.predict(X_test_scaled)
        
        mse = mean_squared_error(y_test, y_pred)
        rmse = np.sqrt(mse)
        r2 = r2_score(y_test, y_pred)
        
        # Validation crois√©e
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')
        
        # G√©n√©rer un nom de mod√®le unique
        base_name = f"regression_{symbol}_{target_param.parameter_name}"
        model_name = base_name
        
        # Trouver la prochaine version disponible
        version_num = 1
        while True:
            version = f"v{version_num}"
            existing = session.query(MLModels).filter(
                MLModels.model_name == model_name,
                MLModels.model_version == version
            ).first()
            if not existing:
                break
            version_num += 1
        
        # Cr√©er les chemins de fichiers avec la version
        model_path = os.path.join(self.models_path, f"{model_name}_{version}.joblib")
        scaler_path = os.path.join(self.models_path, f"{model_name}_{version}_scaler.joblib")
        
        joblib.dump(model, model_path)
        joblib.dump(scaler, scaler_path)
        
        # Enregistrer le mod√®le en base
        ml_model = MLModels(
            model_name=model_name,
            model_type="regression",
            model_version=version,
            symbol=symbol,
            target_parameter_id=target_param.id,
            model_parameters={
                "target_return_percentage": float(target_param.target_return_percentage),
                "time_horizon_days": int(target_param.time_horizon_days),
                "risk_tolerance": str(target_param.risk_tolerance),
                "feature_names": feature_names,
                "training_data_start": str(df['date'].min()),
                "training_data_end": str(df['date'].max())
            },
            performance_metrics={
                "validation_score": float(cv_scores.mean()),
                "test_score": r2,
                "r2_score": r2,
                "mse": mse,
                "rmse": rmse,
                "cv_mean": float(cv_scores.mean()),
                "cv_std": float(cv_scores.std())
            },
            model_path=model_path,
            is_active=True,
            created_by="ml_service"
        )
        session.add(ml_model)
        session.commit()
        
        # Fermer la session si on l'a cr√©√©e
        if should_close_session:
            session.close()
        
        return {
            "success": True,
            "model_id": ml_model.id,
            "model_name": model_name,
            "mse": mse,
            "rmse": rmse,
            "r2_score": r2,
            "cv_mean": float(cv_scores.mean()),
            "cv_std": float(cv_scores.std()),
            "feature_importance": dict(zip(feature_names, model.feature_importances_))
        }
    
    def predict(self, symbol: str, model_id: int, date: datetime, db: Session = None) -> Dict:
        """Faire une pr√©diction avec un mod√®le entra√Æn√©"""
        print(f"üîÆ [PREDICT] D√©but pr√©diction pour {symbol}, model_id: {model_id}")
        print(f"üîÆ [PREDICT] Date: {date}, DB session: {type(db)}")
        
        # Utiliser la session pass√©e en param√®tre ou cr√©er une nouvelle session
        if db is None:
            from app.core.database import SessionLocal
            session = SessionLocal()
            should_close_session = True
            print(f"üîÆ [PREDICT] Session DB cr√©√©e: {type(session)}")
        else:
            session = db
            should_close_session = False
            print(f"üîÆ [PREDICT] Session DB utilis√©e: {type(session)}")
        
        try:
            # R√©cup√©rer le mod√®le
            ml_model = session.query(MLModels).filter(MLModels.id == model_id).first()
            if not ml_model:
                return {"error": "Mod√®le non trouv√©"}
            
            # Charger le mod√®le et le scaler
            model = joblib.load(ml_model.model_path)
            scaler_path = ml_model.model_path.replace('.joblib', '_scaler.joblib')
            scaler = joblib.load(scaler_path)
            
            # R√©cup√©rer les donn√©es du jour avec SQLAlchemy ORM
            # D'abord essayer la date exacte
            historical_data = session.query(HistoricalData).filter(
                HistoricalData.symbol == symbol,
                HistoricalData.date == date
            ).first()
            
            # Si pas de donn√©es pour cette date, prendre la plus r√©cente disponible
            if not historical_data:
                historical_data = session.query(HistoricalData).filter(
                    HistoricalData.symbol == symbol
                ).order_by(HistoricalData.date.desc()).first()
                
                if not historical_data:
                    return {"error": "Aucune donn√©e historique trouv√©e pour ce symbole"}
                
                # Utiliser la date la plus r√©cente trouv√©e
                date = historical_data.date
            
            # R√©cup√©rer les indicateurs techniques
            tech = session.query(TechnicalIndicators).filter(
                TechnicalIndicators.symbol == symbol,
                TechnicalIndicators.date == date
            ).first()
            
            # R√©cup√©rer les indicateurs de sentiment
            sent = session.query(SentimentIndicators).filter(
                SentimentIndicators.symbol == symbol,
                SentimentIndicators.date == date
            ).first()
            
            # Cr√©er le DataFrame avec toutes les dimensions enrichies
            row_data = {
                'close': float(historical_data.close),
                'volume': historical_data.volume,
                'vwap': float(historical_data.vwap) if historical_data.vwap else None,
            }
            
            # Ajouter tous les indicateurs techniques disponibles
            if tech:
            tech_indicators = {
                # Moyennes mobiles
                'sma_5': float(tech.sma_5) if tech.sma_5 else None,
                'sma_10': float(tech.sma_10) if tech.sma_10 else None,
                'sma_20': float(tech.sma_20) if tech.sma_20 else None,
                'sma_50': float(tech.sma_50) if tech.sma_50 else None,
                'sma_200': float(tech.sma_200) if tech.sma_200 else None,
                'ema_5': float(tech.ema_5) if tech.ema_5 else None,
                'ema_10': float(tech.ema_10) if tech.ema_10 else None,
                'ema_20': float(tech.ema_20) if tech.ema_20 else None,
                'ema_50': float(tech.ema_50) if tech.ema_50 else None,
                'ema_200': float(tech.ema_200) if tech.ema_200 else None,
                
                # Indicateurs de momentum
                'rsi_14': float(tech.rsi_14) if tech.rsi_14 else None,
                'macd': float(tech.macd) if tech.macd else None,
                'macd_signal': float(tech.macd_signal) if tech.macd_signal else None,
                'macd_histogram': float(tech.macd_histogram) if tech.macd_histogram else None,
                'stochastic_k': float(tech.stochastic_k) if tech.stochastic_k else None,
                'stochastic_d': float(tech.stochastic_d) if tech.stochastic_d else None,
                'williams_r': float(tech.williams_r) if tech.williams_r else None,
                'roc': float(tech.roc) if tech.roc else None,
                'cci': float(tech.cci) if tech.cci else None,
                
                # Bollinger Bands
                'bb_middle': float(tech.bb_middle) if tech.bb_middle else None,
                'bb_lower': float(tech.bb_lower) if tech.bb_lower else None,
                'bb_width': float(tech.bb_width) if tech.bb_width else None,
                'bb_position': float(tech.bb_position) if tech.bb_position else None,
                
                # Volume
                'obv': float(tech.obv) if tech.obv else None,
                'volume_roc': float(tech.volume_roc) if tech.volume_roc else None,
                'volume_sma_20': float(tech.volume_sma_20) if tech.volume_sma_20 else None,
                
                # ATR
                'atr_14': float(tech.atr_14) if tech.atr_14 else None,
            }
            row_data.update(tech_indicators)
        
        # Ajouter tous les indicateurs de sentiment disponibles
        if sent:
            sent_indicators = {
                # Base Sentiment Indicators
                'sentiment_score_normalized': float(sent.sentiment_score_normalized) if sent.sentiment_score_normalized else None,
                
                # Sentiment Momentum
                'sentiment_momentum_1d': float(sent.sentiment_momentum_1d) if sent.sentiment_momentum_1d else None,
                'sentiment_momentum_3d': float(sent.sentiment_momentum_3d) if sent.sentiment_momentum_3d else None,
                'sentiment_momentum_7d': float(sent.sentiment_momentum_7d) if sent.sentiment_momentum_7d else None,
                'sentiment_momentum_14d': float(sent.sentiment_momentum_14d) if sent.sentiment_momentum_14d else None,
                
                # Sentiment Volatility
                'sentiment_volatility_3d': float(sent.sentiment_volatility_3d) if sent.sentiment_volatility_3d else None,
                'sentiment_volatility_7d': float(sent.sentiment_volatility_7d) if sent.sentiment_volatility_7d else None,
                'sentiment_volatility_14d': float(sent.sentiment_volatility_14d) if sent.sentiment_volatility_14d else None,
                'sentiment_volatility_30d': float(sent.sentiment_volatility_30d) if sent.sentiment_volatility_30d else None,
                
                # Sentiment Moving Averages
                'sentiment_sma_3': float(sent.sentiment_sma_3) if sent.sentiment_sma_3 else None,
                'sentiment_sma_7': float(sent.sentiment_sma_7) if sent.sentiment_sma_7 else None,
                'sentiment_sma_14': float(sent.sentiment_sma_14) if sent.sentiment_sma_14 else None,
                'sentiment_sma_30': float(sent.sentiment_sma_30) if sent.sentiment_sma_30 else None,
                'sentiment_ema_3': float(sent.sentiment_ema_3) if sent.sentiment_ema_3 else None,
                'sentiment_ema_7': float(sent.sentiment_ema_7) if sent.sentiment_ema_7 else None,
                'sentiment_ema_14': float(sent.sentiment_ema_14) if sent.sentiment_ema_14 else None,
                'sentiment_ema_30': float(sent.sentiment_ema_30) if sent.sentiment_ema_30 else None,
                
                # Sentiment Oscillators
                'sentiment_rsi_14': float(sent.sentiment_rsi_14) if sent.sentiment_rsi_14 else None,
                'sentiment_macd': float(sent.sentiment_macd) if sent.sentiment_macd else None,
                'sentiment_macd_signal': float(sent.sentiment_macd_signal) if sent.sentiment_macd_signal else None,
                'sentiment_macd_histogram': float(sent.sentiment_macd_histogram) if sent.sentiment_macd_histogram else None,
                
                # News Volume Indicators
                'news_volume_sma_7': float(sent.news_volume_sma_7) if sent.news_volume_sma_7 else None,
                'news_volume_sma_14': float(sent.news_volume_sma_14) if sent.news_volume_sma_14 else None,
                'news_volume_sma_30': float(sent.news_volume_sma_30) if sent.news_volume_sma_30 else None,
                'news_volume_roc_7d': float(sent.news_volume_roc_7d) if sent.news_volume_roc_7d else None,
                'news_volume_roc_14d': float(sent.news_volume_roc_14d) if sent.news_volume_roc_14d else None,
                
                # Sentiment Distribution Ratios
                'news_positive_ratio': float(sent.news_positive_ratio) if sent.news_positive_ratio else None,
                'news_negative_ratio': float(sent.news_negative_ratio) if sent.news_negative_ratio else None,
                'news_neutral_ratio': float(sent.news_neutral_ratio) if sent.news_neutral_ratio else None,
                'news_sentiment_quality': float(sent.news_sentiment_quality) if sent.news_sentiment_quality else None,
                
                # Short Interest Indicators
                'short_interest_momentum_5d': float(sent.short_interest_momentum_5d) if sent.short_interest_momentum_5d else None,
                'short_interest_momentum_10d': float(sent.short_interest_momentum_10d) if sent.short_interest_momentum_10d else None,
                'short_interest_momentum_20d': float(sent.short_interest_momentum_20d) if sent.short_interest_momentum_20d else None,
                'short_interest_volatility_7d': float(sent.short_interest_volatility_7d) if sent.short_interest_volatility_7d else None,
                'short_interest_volatility_14d': float(sent.short_interest_volatility_14d) if sent.short_interest_volatility_14d else None,
                'short_interest_volatility_30d': float(sent.short_interest_volatility_30d) if sent.short_interest_volatility_30d else None,
                'short_interest_sma_7': float(sent.short_interest_sma_7) if sent.short_interest_sma_7 else None,
                'short_interest_sma_14': float(sent.short_interest_sma_14) if sent.short_interest_sma_14 else None,
                'short_interest_sma_30': float(sent.short_interest_sma_30) if sent.short_interest_sma_30 else None,
                
                # Short Volume Indicators
                'short_volume_momentum_5d': float(sent.short_volume_momentum_5d) if sent.short_volume_momentum_5d else None,
                'short_volume_momentum_10d': float(sent.short_volume_momentum_10d) if sent.short_volume_momentum_10d else None,
                'short_volume_momentum_20d': float(sent.short_volume_momentum_20d) if sent.short_volume_momentum_20d else None,
                'short_volume_volatility_7d': float(sent.short_volume_volatility_7d) if sent.short_volume_volatility_7d else None,
                'short_volume_volatility_14d': float(sent.short_volume_volatility_14d) if sent.short_volume_volatility_14d else None,
                'short_volume_volatility_30d': float(sent.short_volume_volatility_30d) if sent.short_volume_volatility_30d else None,
                
                # Composite Sentiment Indicators
                'sentiment_strength_index': float(sent.sentiment_strength_index) if sent.sentiment_strength_index else None,
                'market_sentiment_index': float(sent.market_sentiment_index) if sent.market_sentiment_index else None,
                'sentiment_divergence': float(sent.sentiment_divergence) if sent.sentiment_divergence else None,
                'sentiment_acceleration': float(sent.sentiment_acceleration) if sent.sentiment_acceleration else None,
                'sentiment_trend_strength': float(sent.sentiment_trend_strength) if sent.sentiment_trend_strength else None,
                'sentiment_quality_index': float(sent.sentiment_quality_index) if sent.sentiment_quality_index else None,
                'sentiment_risk_score': float(sent.sentiment_risk_score) if sent.sentiment_risk_score else None,
            }
            row_data.update(sent_indicators)
        
        data = [row_data]
        
        df = pd.DataFrame(data)
        
        if df.empty:
            return {"error": "Donn√©es non trouv√©es pour cette date"}
        
        # R√©cup√©rer les noms des features utilis√©es lors de l'entra√Ænement
        feature_names = ml_model.model_parameters.get('feature_names', [])
        if not feature_names:
            return {"error": "Noms des features non trouv√©s dans le mod√®le"}
        
        # Pr√©parer les features en utilisant exactement les m√™mes features que l'entra√Ænement
        X = self.prepare_features_for_prediction(df, feature_names)
        
        # Normaliser et pr√©dire
        X_scaled = scaler.transform(X)
        
        if ml_model.model_type == "classification":
            prediction = model.predict(X_scaled)[0]
            confidence = model.predict_proba(X_scaled)[0].max()
            prediction_type = "target_achieved"
        else:  # regression
            prediction = model.predict(X_scaled)[0]
            confidence = 0.8  # Placeholder pour la r√©gression
            prediction_type = "target_return"
        
        # Enregistrer la pr√©diction
        ml_prediction = MLPredictions(
            symbol=symbol,
            prediction_date=date,
            model_id=model_id,
            prediction_class=prediction_type,
            prediction_value=float(prediction),
            confidence=float(confidence),
            data_date_used=date,
            created_by="ml_service"
        )
        session.add(ml_prediction)
        session.commit()
        
        # Fermer la session si on l'a cr√©√©e
        if should_close_session:
            session.close()
        
        return {
            "symbol": symbol,
            "date": date,
            "prediction": float(prediction),
            "confidence": float(confidence),
            "prediction_type": prediction_type,
            "model_name": ml_model.model_name,
            "data_date_used": date  # Indiquer la date r√©ellement utilis√©e
        }
        
        except Exception as e:
            print(f"‚ùå [PREDICT] Erreur pr√©diction {symbol}: {str(e)}")
            print(f"‚ùå [PREDICT] Type d'erreur: {type(e).__name__}")
            import traceback
            print(f"‚ùå [PREDICT] Traceback: {traceback.format_exc()}")
            
            # Fermer la session si on l'a cr√©√©e
            if should_close_session:
                session.close()
            
            return {"error": f"Erreur lors de la pr√©diction: {str(e)}"}
    
    def get_model_performance(self, model_id: int, db: Session = None) -> Dict:
        """R√©cup√©rer les performances d'un mod√®le"""
        # Utiliser la session pass√©e en param√®tre ou celle de l'instance
        session = db or self.db
        
        ml_model = session.query(MLModels).filter(MLModels.id == model_id).first()
        if not ml_model:
            return {"error": "Mod√®le non trouv√©"}
        
        # R√©cup√©rer les pr√©dictions r√©centes
        recent_predictions = session.query(MLPredictions).filter(
            MLPredictions.model_id == model_id
        ).order_by(MLPredictions.prediction_date.desc()).limit(100).all()
        
        return {
            "model_id": ml_model.id,
            "model_name": ml_model.model_name,
            "model_type": ml_model.model_type,
            "validation_score": float(ml_model.validation_score) if ml_model.validation_score else None,
            "test_score": float(ml_model.test_score) if ml_model.test_score else None,
            "training_period": {
                "start": ml_model.training_data_start.isoformat() if ml_model.training_data_start else None,
                "end": ml_model.training_data_end.isoformat() if ml_model.training_data_end else None
            },
            "recent_predictions_count": len(recent_predictions),
            "is_active": ml_model.is_active
        }
    
    def calculate_shap_explanations(self, model_id: int, symbol: str, prediction_date: date, db: Session = None) -> Dict:
        """Calculer les explications SHAP pour une pr√©diction"""
        # Utiliser la session pass√©e en param√®tre ou celle de l'instance
        session = db or self.db
        
        # R√©cup√©rer le mod√®le
        ml_model = session.query(MLModels).filter(MLModels.id == model_id).first()
        if not ml_model:
            return {"error": "Mod√®le non trouv√©"}
        
        # Charger le mod√®le et le scaler
        model = joblib.load(ml_model.model_path)
        scaler_path = ml_model.model_path.replace('.joblib', '_scaler.joblib')
        scaler = joblib.load(scaler_path)
        
        # R√©cup√©rer les donn√©es du jour
        historical_data = session.query(HistoricalData).filter(
            HistoricalData.symbol == symbol,
            HistoricalData.date == prediction_date
        ).first()
        
        if not historical_data:
            # Prendre la plus r√©cente disponible
            historical_data = session.query(HistoricalData).filter(
                HistoricalData.symbol == symbol
            ).order_by(HistoricalData.date.desc()).first()
            
            if not historical_data:
                return {"error": "Aucune donn√©e historique trouv√©e pour ce symbole"}
        
        # R√©cup√©rer les indicateurs techniques et de sentiment
        tech = session.query(TechnicalIndicators).filter(
            TechnicalIndicators.symbol == symbol,
            TechnicalIndicators.date == historical_data.date
        ).first()
        
        sent = session.query(SentimentIndicators).filter(
            SentimentIndicators.symbol == symbol,
            SentimentIndicators.date == historical_data.date
        ).first()
        
        # Cr√©er le DataFrame avec toutes les dimensions enrichies
        row_data = {
            'close': float(historical_data.close),
            'volume': historical_data.volume,
            'vwap': float(historical_data.vwap) if historical_data.vwap else None,
        }
        
        # Ajouter tous les indicateurs techniques disponibles
        if tech:
            tech_indicators = {
                # Moyennes mobiles
                'sma_5': float(tech.sma_5) if tech.sma_5 else None,
                'sma_10': float(tech.sma_10) if tech.sma_10 else None,
                'sma_20': float(tech.sma_20) if tech.sma_20 else None,
                'sma_50': float(tech.sma_50) if tech.sma_50 else None,
                'sma_200': float(tech.sma_200) if tech.sma_200 else None,
                'ema_5': float(tech.ema_5) if tech.ema_5 else None,
                'ema_10': float(tech.ema_10) if tech.ema_10 else None,
                'ema_20': float(tech.ema_20) if tech.ema_20 else None,
                'ema_50': float(tech.ema_50) if tech.ema_50 else None,
                'ema_200': float(tech.ema_200) if tech.ema_200 else None,
                
                # Indicateurs de momentum
                'rsi_14': float(tech.rsi_14) if tech.rsi_14 else None,
                'macd': float(tech.macd) if tech.macd else None,
                'macd_signal': float(tech.macd_signal) if tech.macd_signal else None,
                'macd_histogram': float(tech.macd_histogram) if tech.macd_histogram else None,
                'stochastic_k': float(tech.stochastic_k) if tech.stochastic_k else None,
                'stochastic_d': float(tech.stochastic_d) if tech.stochastic_d else None,
                'williams_r': float(tech.williams_r) if tech.williams_r else None,
                'roc': float(tech.roc) if tech.roc else None,
                'cci': float(tech.cci) if tech.cci else None,
                
                # Bollinger Bands
                'bb_middle': float(tech.bb_middle) if tech.bb_middle else None,
                'bb_lower': float(tech.bb_lower) if tech.bb_lower else None,
                'bb_width': float(tech.bb_width) if tech.bb_width else None,
                'bb_position': float(tech.bb_position) if tech.bb_position else None,
                
                # Volume
                'obv': float(tech.obv) if tech.obv else None,
                'volume_roc': float(tech.volume_roc) if tech.volume_roc else None,
                'volume_sma_20': float(tech.volume_sma_20) if tech.volume_sma_20 else None,
                
                # ATR
                'atr_14': float(tech.atr_14) if tech.atr_14 else None,
            }
            row_data.update(tech_indicators)
        
        # Ajouter tous les indicateurs de sentiment disponibles
        if sent:
            sent_indicators = {
                # Base Sentiment Indicators
                'sentiment_score_normalized': float(sent.sentiment_score_normalized) if sent.sentiment_score_normalized else None,
                
                # Sentiment Momentum
                'sentiment_momentum_1d': float(sent.sentiment_momentum_1d) if sent.sentiment_momentum_1d else None,
                'sentiment_momentum_3d': float(sent.sentiment_momentum_3d) if sent.sentiment_momentum_3d else None,
                'sentiment_momentum_7d': float(sent.sentiment_momentum_7d) if sent.sentiment_momentum_7d else None,
                'sentiment_momentum_14d': float(sent.sentiment_momentum_14d) if sent.sentiment_momentum_14d else None,
                
                # Sentiment Volatility
                'sentiment_volatility_3d': float(sent.sentiment_volatility_3d) if sent.sentiment_volatility_3d else None,
                'sentiment_volatility_7d': float(sent.sentiment_volatility_7d) if sent.sentiment_volatility_7d else None,
                'sentiment_volatility_14d': float(sent.sentiment_volatility_14d) if sent.sentiment_volatility_14d else None,
                'sentiment_volatility_30d': float(sent.sentiment_volatility_30d) if sent.sentiment_volatility_30d else None,
                
                # Sentiment Moving Averages
                'sentiment_sma_3': float(sent.sentiment_sma_3) if sent.sentiment_sma_3 else None,
                'sentiment_sma_7': float(sent.sentiment_sma_7) if sent.sentiment_sma_7 else None,
                'sentiment_sma_14': float(sent.sentiment_sma_14) if sent.sentiment_sma_14 else None,
                'sentiment_sma_30': float(sent.sentiment_sma_30) if sent.sentiment_sma_30 else None,
                'sentiment_ema_3': float(sent.sentiment_ema_3) if sent.sentiment_ema_3 else None,
                'sentiment_ema_7': float(sent.sentiment_ema_7) if sent.sentiment_ema_7 else None,
                'sentiment_ema_14': float(sent.sentiment_ema_14) if sent.sentiment_ema_14 else None,
                'sentiment_ema_30': float(sent.sentiment_ema_30) if sent.sentiment_ema_30 else None,
                
                # Sentiment Oscillators
                'sentiment_rsi_14': float(sent.sentiment_rsi_14) if sent.sentiment_rsi_14 else None,
                'sentiment_macd': float(sent.sentiment_macd) if sent.sentiment_macd else None,
                'sentiment_macd_signal': float(sent.sentiment_macd_signal) if sent.sentiment_macd_signal else None,
                'sentiment_macd_histogram': float(sent.sentiment_macd_histogram) if sent.sentiment_macd_histogram else None,
                
                # News Volume Indicators
                'news_volume_sma_7': float(sent.news_volume_sma_7) if sent.news_volume_sma_7 else None,
                'news_volume_sma_14': float(sent.news_volume_sma_14) if sent.news_volume_sma_14 else None,
                'news_volume_sma_30': float(sent.news_volume_sma_30) if sent.news_volume_sma_30 else None,
                'news_volume_roc_7d': float(sent.news_volume_roc_7d) if sent.news_volume_roc_7d else None,
                'news_volume_roc_14d': float(sent.news_volume_roc_14d) if sent.news_volume_roc_14d else None,
                
                # Sentiment Distribution Ratios
                'news_positive_ratio': float(sent.news_positive_ratio) if sent.news_positive_ratio else None,
                'news_negative_ratio': float(sent.news_negative_ratio) if sent.news_negative_ratio else None,
                'news_neutral_ratio': float(sent.news_neutral_ratio) if sent.news_neutral_ratio else None,
                'news_sentiment_quality': float(sent.news_sentiment_quality) if sent.news_sentiment_quality else None,
                
                # Short Interest Indicators
                'short_interest_momentum_5d': float(sent.short_interest_momentum_5d) if sent.short_interest_momentum_5d else None,
                'short_interest_momentum_10d': float(sent.short_interest_momentum_10d) if sent.short_interest_momentum_10d else None,
                'short_interest_momentum_20d': float(sent.short_interest_momentum_20d) if sent.short_interest_momentum_20d else None,
                'short_interest_volatility_7d': float(sent.short_interest_volatility_7d) if sent.short_interest_volatility_7d else None,
                'short_interest_volatility_14d': float(sent.short_interest_volatility_14d) if sent.short_interest_volatility_14d else None,
                'short_interest_volatility_30d': float(sent.short_interest_volatility_30d) if sent.short_interest_volatility_30d else None,
                'short_interest_sma_7': float(sent.short_interest_sma_7) if sent.short_interest_sma_7 else None,
                'short_interest_sma_14': float(sent.short_interest_sma_14) if sent.short_interest_sma_14 else None,
                'short_interest_sma_30': float(sent.short_interest_sma_30) if sent.short_interest_sma_30 else None,
                
                # Short Volume Indicators
                'short_volume_momentum_5d': float(sent.short_volume_momentum_5d) if sent.short_volume_momentum_5d else None,
                'short_volume_momentum_10d': float(sent.short_volume_momentum_10d) if sent.short_volume_momentum_10d else None,
                'short_volume_momentum_20d': float(sent.short_volume_momentum_20d) if sent.short_volume_momentum_20d else None,
                'short_volume_volatility_7d': float(sent.short_volume_volatility_7d) if sent.short_volume_volatility_7d else None,
                'short_volume_volatility_14d': float(sent.short_volume_volatility_14d) if sent.short_volume_volatility_14d else None,
                'short_volume_volatility_30d': float(sent.short_volume_volatility_30d) if sent.short_volume_volatility_30d else None,
                
                # Composite Sentiment Indicators
                'sentiment_strength_index': float(sent.sentiment_strength_index) if sent.sentiment_strength_index else None,
                'market_sentiment_index': float(sent.market_sentiment_index) if sent.market_sentiment_index else None,
                'sentiment_divergence': float(sent.sentiment_divergence) if sent.sentiment_divergence else None,
                'sentiment_acceleration': float(sent.sentiment_acceleration) if sent.sentiment_acceleration else None,
                'sentiment_trend_strength': float(sent.sentiment_trend_strength) if sent.sentiment_trend_strength else None,
                'sentiment_quality_index': float(sent.sentiment_quality_index) if sent.sentiment_quality_index else None,
                'sentiment_risk_score': float(sent.sentiment_risk_score) if sent.sentiment_risk_score else None,
            }
            row_data.update(sent_indicators)
        
        data = [row_data]
        
        df = pd.DataFrame(data)
        
        # Remplacer les valeurs NaN avec toutes les colonnes enrichies
        numeric_columns = [
            # Donn√©es de base
            'close', 'volume', 'vwap',
            
            # Moyennes mobiles techniques
            'sma_5', 'sma_10', 'sma_20', 'sma_50', 'sma_200',
            'ema_5', 'ema_10', 'ema_20', 'ema_50', 'ema_200',
            
            # Indicateurs de momentum techniques
            'rsi_14', 'macd', 'macd_signal', 'macd_histogram',
            'stochastic_k', 'stochastic_d', 'williams_r', 'roc', 'cci',
            
            # Bollinger Bands
            'bb_middle', 'bb_lower', 'bb_width', 'bb_position',
            
            # Volume techniques
            'obv', 'volume_roc', 'volume_sma_20',
            
            # ATR
            'atr_14',
            
            # Indicateurs de sentiment de base
            'sentiment_score_normalized',
            
            # Sentiment Momentum
            'sentiment_momentum_1d', 'sentiment_momentum_3d', 'sentiment_momentum_7d', 'sentiment_momentum_14d',
            
            # Sentiment Volatility
            'sentiment_volatility_3d', 'sentiment_volatility_7d', 'sentiment_volatility_14d', 'sentiment_volatility_30d',
            
            # Sentiment Moving Averages
            'sentiment_sma_3', 'sentiment_sma_7', 'sentiment_sma_14', 'sentiment_sma_30',
            'sentiment_ema_3', 'sentiment_ema_7', 'sentiment_ema_14', 'sentiment_ema_30',
            
            # Sentiment Oscillators
            'sentiment_rsi_14', 'sentiment_macd', 'sentiment_macd_signal', 'sentiment_macd_histogram',
            
            # News Volume Indicators
            'news_volume_sma_7', 'news_volume_sma_14', 'news_volume_sma_30',
            'news_volume_roc_7d', 'news_volume_roc_14d',
            
            # Sentiment Distribution Ratios
            'news_positive_ratio', 'news_negative_ratio', 'news_neutral_ratio', 'news_sentiment_quality',
            
            # Short Interest Indicators
            'short_interest_momentum_5d', 'short_interest_momentum_10d', 'short_interest_momentum_20d',
            'short_interest_volatility_7d', 'short_interest_volatility_14d', 'short_interest_volatility_30d',
            'short_interest_sma_7', 'short_interest_sma_14', 'short_interest_sma_30',
            
            # Short Volume Indicators
            'short_volume_momentum_5d', 'short_volume_momentum_10d', 'short_volume_momentum_20d',
            'short_volume_volatility_7d', 'short_volume_volatility_14d', 'short_volume_volatility_30d',
            
            # Composite Sentiment Indicators
            'sentiment_strength_index', 'market_sentiment_index', 'sentiment_divergence',
            'sentiment_acceleration', 'sentiment_trend_strength', 'sentiment_quality_index', 'sentiment_risk_score'
        ]
        
        for col in numeric_columns:
            if col in df.columns:
                median_val = df[col].median() if not df[col].isna().all() else 0
                df[col] = df[col].fillna(median_val)
        
        # R√©cup√©rer les noms des features utilis√©es lors de l'entra√Ænement
        feature_names = ml_model.model_parameters.get('feature_names', [])
        if not feature_names:
            return {"error": "Noms des features non trouv√©s dans le mod√®le"}
        
        # Utiliser la m√©thode prepare_features_for_prediction pour garantir la coh√©rence
        X = self.prepare_features_for_prediction(df, feature_names)
        
        # Normaliser
        X_scaled = scaler.transform(X)
        feature_names = list(X.columns)
        
        # Calculer les explications SHAP
        try:
            # Cr√©er un explainer SHAP pour Random Forest
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(X_scaled)
            
            # Gestion sp√©cifique pour la classification et la r√©gression
            prediction = model.predict(X_scaled)[0]
            
            if ml_model.model_type == "classification":
                # Pour la classification binaire, toujours prendre la classe positive (1)
                if isinstance(shap_values, list) and len(shap_values) == 2:
                    shap_values = shap_values[1]  # Classe positive
                elif isinstance(shap_values, list):
                    shap_values = shap_values[int(prediction)]
                
                # S'assurer que shap_values est un array 1D
                if hasattr(shap_values, 'shape') and len(shap_values.shape) > 1:
                    shap_values = shap_values.flatten()
                    
                base_value = explainer.expected_value[1] if isinstance(explainer.expected_value, (list, np.ndarray)) and len(explainer.expected_value) > 1 else explainer.expected_value
            else:
                # R√©gression
                if isinstance(shap_values, list):
                    shap_values = shap_values[0]
                
                # S'assurer que shap_values est un array 1D
                if hasattr(shap_values, 'shape') and len(shap_values.shape) > 1:
                    shap_values = shap_values.flatten()
                    
                base_value = explainer.expected_value
            
            # Cr√©er les explications
            explanations = []
            for i, feature in enumerate(feature_names):
                explanations.append({
                    "feature": feature,
                    "shap_value": float(shap_values[i]),
                    "feature_value": float(X.iloc[0, i]),
                    "impact": "positive" if shap_values[i] > 0 else "negative"
                })
            
            # Trier par importance (valeur absolue de SHAP) puis par sens (positif d'abord, n√©gatif ensuite)
            explanations.sort(key=lambda x: (-abs(x["shap_value"]), x["shap_value"] < 0))
            
            return {
                "model_id": model_id,
                "model_name": ml_model.model_name,
                "model_type": ml_model.model_type,
                "symbol": symbol,
                "prediction_date": historical_data.date,
                "prediction": float(model.predict(X_scaled)[0]),
                "shap_explanations": explanations,
                "base_value": float(base_value) if hasattr(base_value, '__float__') else 0.0
            }
            
        except Exception as e:
            return {"error": f"Erreur lors du calcul SHAP: {str(e)}"}
    
    def get_model_feature_importance(self, model_id: int, db: Session = None) -> Dict:
        """R√©cup√©rer l'importance des features d'un mod√®le"""
        # Utiliser la session pass√©e en param√®tre ou celle de l'instance
        session = db or self.db
        
        # R√©cup√©rer le mod√®le
        ml_model = session.query(MLModels).filter(MLModels.id == model_id).first()
        if not ml_model:
            return {"error": "Mod√®le non trouv√©"}
        
        # Charger le mod√®le
        model = joblib.load(ml_model.model_path)
        
        # R√©cup√©rer les feature importances
        if hasattr(model, 'feature_importances_'):
            feature_names = ml_model.model_parameters.get("feature_names", [])
            importances = model.feature_importances_
            
            # Cr√©er la liste des importances
            importance_list = []
            for i, feature in enumerate(feature_names):
                if i < len(importances):
                    importance_list.append({
                        "feature": feature,
                        "importance": float(importances[i])
                    })
            
            # Trier par importance
            importance_list.sort(key=lambda x: x["importance"], reverse=True)
            
            return {
                "model_id": model_id,
                "model_name": ml_model.model_name,
                "model_type": ml_model.model_type,
                "feature_importances": importance_list
            }
        else:
            return {"error": "Ce type de mod√®le ne supporte pas l'importance des features"}
