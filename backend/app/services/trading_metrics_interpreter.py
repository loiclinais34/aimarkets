"""
Service d'interpr√©tation des m√©triques de trading
================================================

Ce service fournit des interpr√©tations intelligentes et des recommandations
bas√©es sur les m√©triques calcul√©es par le framework de comparaison.
"""

import logging
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class RiskLevel(Enum):
    """Niveaux de risque pour les mod√®les"""
    VERY_LOW = "very_low"
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    VERY_HIGH = "very_high"
    CRITICAL = "critical"

class PerformanceGrade(Enum):
    """Notes de performance"""
    EXCELLENT = "A+"
    VERY_GOOD = "A"
    GOOD = "B"
    AVERAGE = "C"
    POOR = "D"
    FAILING = "F"

@dataclass
class MetricInterpretation:
    """Interpr√©tation d'une m√©trique"""
    value: float
    grade: PerformanceGrade
    interpretation: str
    recommendation: str
    risk_level: RiskLevel
    color: str

@dataclass
class ModelAnalysis:
    """Analyse compl√®te d'un mod√®le"""
    model_name: str
    overall_grade: PerformanceGrade
    risk_level: RiskLevel
    is_tradable: bool
    confidence_score: float
    key_strengths: List[str]
    key_weaknesses: List[str]
    recommendations: List[str]
    warnings: List[str]
    metrics_analysis: Dict[str, MetricInterpretation]

class TradingMetricsInterpreter:
    """Interpr√®te les m√©triques de trading et fournit des recommandations"""
    
    def __init__(self):
        self.risk_thresholds = {
            'sharpe_ratio': {
                'excellent': 2.0,
                'good': 1.0,
                'acceptable': 0.5,
                'poor': 0.0,
                'critical': -1.0
            },
            'total_return': {
                'excellent': 0.20,  # 20%
                'good': 0.10,      # 10%
                'acceptable': 0.05, # 5%
                'poor': 0.0,       # 0%
                'critical': -0.05   # -5%
            },
            'max_drawdown': {
                'excellent': 0.05,  # 5%
                'good': 0.10,      # 10%
                'acceptable': 0.15, # 15%
                'poor': 0.25,      # 25%
                'critical': 0.50    # 50%
            },
            'win_rate': {
                'excellent': 0.70,  # 70%
                'good': 0.60,       # 60%
                'acceptable': 0.50, # 50%
                'poor': 0.40,      # 40%
                'critical': 0.30   # 30%
            },
            'profit_factor': {
                'excellent': 2.0,
                'good': 1.5,
                'acceptable': 1.2,
                'poor': 1.0,
                'critical': 0.8
            },
            'accuracy': {
                'excellent': 0.80,  # 80%
                'good': 0.70,       # 70%
                'acceptable': 0.60, # 60%
                'poor': 0.50,       # 50%
                'critical': 0.40    # 40%
            },
            'f1_score': {
                'excellent': 0.80,  # 80%
                'good': 0.70,       # 70%
                'acceptable': 0.60, # 60%
                'poor': 0.50,       # 50%
                'critical': 0.40     # 40%
            }
        }
    
    def interpret_sharpe_ratio(self, sharpe: float) -> MetricInterpretation:
        """Interpr√®te le Sharpe Ratio"""
        if sharpe >= 2.0:
            grade = PerformanceGrade.EXCELLENT
            interpretation = f"Sharpe Ratio exceptionnel ({sharpe:.3f}). Le mod√®le g√©n√®re un rendement exc√©dentaire tr√®s √©lev√© par rapport au risque pris."
            recommendation = "Mod√®le recommand√© pour un portefeuille agressif. Excellent √©quilibre rendement/risque."
            risk_level = RiskLevel.VERY_LOW
            color = "text-green-600"
        elif sharpe >= 1.0:
            grade = PerformanceGrade.VERY_GOOD
            interpretation = f"Sharpe Ratio tr√®s bon ({sharpe:.3f}). Bon √©quilibre entre rendement et risque."
            recommendation = "Mod√®le recommand√© pour la plupart des strat√©gies. Performance solide."
            risk_level = RiskLevel.LOW
            color = "text-green-500"
        elif sharpe >= 0.5:
            grade = PerformanceGrade.GOOD
            interpretation = f"Sharpe Ratio acceptable ({sharpe:.3f}). Rendement mod√©r√© pour le risque pris."
            recommendation = "Mod√®le utilisable avec prudence. Surveiller les performances."
            risk_level = RiskLevel.MEDIUM
            color = "text-yellow-500"
        elif sharpe >= 0.0:
            grade = PerformanceGrade.AVERAGE
            interpretation = f"Sharpe Ratio faible ({sharpe:.3f}). Rendement insuffisant pour le risque."
            recommendation = "Mod√®le non recommand√©. Consid√©rer des am√©liorations avant utilisation."
            risk_level = RiskLevel.HIGH
            color = "text-orange-500"
        else:
            grade = PerformanceGrade.FAILING
            interpretation = f"Sharpe Ratio n√©gatif ({sharpe:.3f}). Le mod√®le g√©n√®re des pertes par rapport au risque pris."
            recommendation = "‚ö†Ô∏è ATTENTION: Ce mod√®le fait perdre de l'argent. Ne pas utiliser pour du trading r√©el."
            risk_level = RiskLevel.CRITICAL
            color = "text-red-600"
        
        return MetricInterpretation(
            value=sharpe,
            grade=grade,
            interpretation=interpretation,
            recommendation=recommendation,
            risk_level=risk_level,
            color=color
        )
    
    def interpret_total_return(self, return_pct: float) -> MetricInterpretation:
        """Interpr√®te le rendement total"""
        if return_pct >= 0.20:
            grade = PerformanceGrade.EXCELLENT
            interpretation = f"Rendement exceptionnel ({return_pct:.1%}). Le mod√®le g√©n√®re des profits tr√®s √©lev√©s."
            recommendation = "Excellent mod√®le pour la croissance du capital. Surveiller la volatilit√©."
            risk_level = RiskLevel.LOW
            color = "text-green-600"
        elif return_pct >= 0.10:
            grade = PerformanceGrade.VERY_GOOD
            interpretation = f"Rendement tr√®s bon ({return_pct:.1%}). Performance solide et rentable."
            recommendation = "Mod√®le recommand√© pour la plupart des objectifs d'investissement."
            risk_level = RiskLevel.LOW
            color = "text-green-500"
        elif return_pct >= 0.05:
            grade = PerformanceGrade.GOOD
            interpretation = f"Rendement acceptable ({return_pct:.1%}). Performance mod√©r√©e mais positive."
            recommendation = "Mod√®le utilisable avec des attentes r√©alistes. Bon pour la pr√©servation du capital."
            risk_level = RiskLevel.MEDIUM
            color = "text-yellow-500"
        elif return_pct >= 0.0:
            grade = PerformanceGrade.AVERAGE
            interpretation = f"Rendement faible ({return_pct:.1%}). Performance insuffisante."
            recommendation = "Mod√®le non recommand√©. Consid√©rer des am√©liorations ou des alternatives."
            risk_level = RiskLevel.HIGH
            color = "text-orange-500"
        else:
            grade = PerformanceGrade.FAILING
            interpretation = f"Rendement n√©gatif ({return_pct:.1%}). Le mod√®le fait perdre de l'argent."
            recommendation = "üö® DANGER: Ce mod√®le g√©n√®re des pertes. Arr√™ter imm√©diatement toute utilisation."
            risk_level = RiskLevel.CRITICAL
            color = "text-red-600"
        
        return MetricInterpretation(
            value=return_pct,
            grade=grade,
            interpretation=interpretation,
            recommendation=recommendation,
            risk_level=risk_level,
            color=color
        )
    
    def interpret_max_drawdown(self, drawdown: float) -> MetricInterpretation:
        """Interpr√®te le drawdown maximum"""
        if drawdown <= 0.05:
            grade = PerformanceGrade.EXCELLENT
            interpretation = f"Drawdown tr√®s faible ({drawdown:.1%}). Le mod√®le est tr√®s stable."
            recommendation = "Excellent pour les investisseurs conservateurs. Risque minimal."
            risk_level = RiskLevel.VERY_LOW
            color = "text-green-600"
        elif drawdown <= 0.10:
            grade = PerformanceGrade.VERY_GOOD
            interpretation = f"Drawdown faible ({drawdown:.1%}). Le mod√®le est relativement stable."
            recommendation = "Bon pour la plupart des profils de risque. Surveillance normale requise."
            risk_level = RiskLevel.LOW
            color = "text-green-500"
        elif drawdown <= 0.15:
            grade = PerformanceGrade.GOOD
            interpretation = f"Drawdown mod√©r√© ({drawdown:.1%}). Volatilit√© acceptable."
            recommendation = "Acceptable pour les investisseurs mod√©r√©s. Surveiller les p√©riodes de stress."
            risk_level = RiskLevel.MEDIUM
            color = "text-yellow-500"
        elif drawdown <= 0.25:
            grade = PerformanceGrade.AVERAGE
            interpretation = f"Drawdown √©lev√© ({drawdown:.1%}). Le mod√®le est volatil."
            recommendation = "R√©serv√© aux investisseurs agressifs. Risque de pertes importantes."
            risk_level = RiskLevel.HIGH
            color = "text-orange-500"
        else:
            grade = PerformanceGrade.FAILING
            interpretation = f"Drawdown critique ({drawdown:.1%}). Le mod√®le est extr√™mement volatil."
            recommendation = "‚ö†Ô∏è RISQUE √âLEV√â: Perte de capital importante possible. Utilisation d√©conseill√©e."
            risk_level = RiskLevel.CRITICAL
            color = "text-red-600"
        
        return MetricInterpretation(
            value=drawdown,
            grade=grade,
            interpretation=interpretation,
            recommendation=recommendation,
            risk_level=risk_level,
            color=color
        )
    
    def interpret_win_rate(self, win_rate: float) -> MetricInterpretation:
        """Interpr√®te le taux de r√©ussite"""
        if win_rate >= 0.70:
            grade = PerformanceGrade.EXCELLENT
            interpretation = f"Taux de r√©ussite exceptionnel ({win_rate:.1%}). Le mod√®le pr√©dit correctement dans la plupart des cas."
            recommendation = "Mod√®le tr√®s fiable. Excellent pour la confiance des traders."
            risk_level = RiskLevel.VERY_LOW
            color = "text-green-600"
        elif win_rate >= 0.60:
            grade = PerformanceGrade.VERY_GOOD
            interpretation = f"Taux de r√©ussite tr√®s bon ({win_rate:.1%}). Pr√©dictions g√©n√©ralement correctes."
            recommendation = "Mod√®le fiable. Bon pour la plupart des strat√©gies."
            risk_level = RiskLevel.LOW
            color = "text-green-500"
        elif win_rate >= 0.50:
            grade = PerformanceGrade.GOOD
            interpretation = f"Taux de r√©ussite acceptable ({win_rate:.1%}). Pr√©dictions moyennement fiables."
            recommendation = "Mod√®le utilisable avec prudence. Surveiller la qualit√© des signaux."
            risk_level = RiskLevel.MEDIUM
            color = "text-yellow-500"
        elif win_rate >= 0.40:
            grade = PerformanceGrade.AVERAGE
            interpretation = f"Taux de r√©ussite faible ({win_rate:.1%}). Pr√©dictions peu fiables."
            recommendation = "Mod√®le non recommand√©. Am√©liorer la pr√©cision avant utilisation."
            risk_level = RiskLevel.HIGH
            color = "text-orange-500"
        else:
            grade = PerformanceGrade.FAILING
            interpretation = f"Taux de r√©ussite critique ({win_rate:.1%}). Le mod√®le pr√©dit incorrectement la plupart du temps."
            recommendation = "üö® DANGER: Ce mod√®le est contre-productif. Arr√™ter imm√©diatement."
            risk_level = RiskLevel.CRITICAL
            color = "text-red-600"
        
        return MetricInterpretation(
            value=win_rate,
            grade=grade,
            interpretation=interpretation,
            recommendation=recommendation,
            risk_level=risk_level,
            color=color
        )
    
    def interpret_accuracy(self, accuracy: float) -> MetricInterpretation:
        """Interpr√®te l'accuracy du mod√®le ML"""
        if accuracy >= 0.80:
            grade = PerformanceGrade.EXCELLENT
            interpretation = f"Accuracy exceptionnelle ({accuracy:.1%}). Le mod√®le ML est tr√®s pr√©cis."
            recommendation = "Mod√®le ML tr√®s fiable. Excellent pour la prise de d√©cision automatis√©e."
            risk_level = RiskLevel.VERY_LOW
            color = "text-green-600"
        elif accuracy >= 0.70:
            grade = PerformanceGrade.VERY_GOOD
            interpretation = f"Accuracy tr√®s bonne ({accuracy:.1%}). Le mod√®le ML est pr√©cis."
            recommendation = "Mod√®le ML fiable. Bon pour la plupart des applications."
            risk_level = RiskLevel.LOW
            color = "text-green-500"
        elif accuracy >= 0.60:
            grade = PerformanceGrade.GOOD
            interpretation = f"Accuracy acceptable ({accuracy:.1%}). Le mod√®le ML est moyennement pr√©cis."
            recommendation = "Mod√®le ML utilisable avec prudence. Surveiller les performances."
            risk_level = RiskLevel.MEDIUM
            color = "text-yellow-500"
        elif accuracy >= 0.50:
            grade = PerformanceGrade.AVERAGE
            interpretation = f"Accuracy faible ({accuracy:.1%}). Le mod√®le ML manque de pr√©cision."
            recommendation = "Mod√®le ML non recommand√©. Am√©liorer l'entra√Ænement avant utilisation."
            risk_level = RiskLevel.HIGH
            color = "text-orange-500"
        else:
            grade = PerformanceGrade.FAILING
            interpretation = f"Accuracy critique ({accuracy:.1%}). Le mod√®le ML est contre-productif."
            recommendation = "üö® DANGER: Ce mod√®le ML fait plus de mal que de bien. Arr√™ter imm√©diatement."
            risk_level = RiskLevel.CRITICAL
            color = "text-red-600"
        
        return MetricInterpretation(
            value=accuracy,
            grade=grade,
            interpretation=interpretation,
            recommendation=recommendation,
            risk_level=risk_level,
            color=color
        )
    
    def analyze_model(self, model_name: str, metrics: Dict[str, Any]) -> ModelAnalysis:
        """Analyse compl√®te d'un mod√®le bas√©e sur toutes ses m√©triques"""
        
        # Nettoyer les m√©triques (remplacer None par 0)
        cleaned_metrics = {}
        for key, value in metrics.items():
            if value is None:
                cleaned_metrics[key] = 0.0
            else:
                cleaned_metrics[key] = value
        
        # Interpr√©ter chaque m√©trique
        metrics_analysis = {}
        
        if 'sharpe_ratio' in cleaned_metrics:
            metrics_analysis['sharpe_ratio'] = self.interpret_sharpe_ratio(cleaned_metrics['sharpe_ratio'])
        
        if 'total_return' in cleaned_metrics:
            metrics_analysis['total_return'] = self.interpret_total_return(cleaned_metrics['total_return'])
        
        if 'max_drawdown' in cleaned_metrics:
            metrics_analysis['max_drawdown'] = self.interpret_max_drawdown(cleaned_metrics['max_drawdown'])
        
        if 'win_rate' in cleaned_metrics:
            metrics_analysis['win_rate'] = self.interpret_win_rate(cleaned_metrics['win_rate'])
        
        if 'accuracy' in cleaned_metrics:
            metrics_analysis['accuracy'] = self.interpret_accuracy(cleaned_metrics['accuracy'])
        
        # Calculer la note globale
        grades = [m.grade for m in metrics_analysis.values()]
        overall_grade = self._calculate_overall_grade(grades)
        
        # D√©terminer le niveau de risque global
        risk_levels = [m.risk_level for m in metrics_analysis.values()]
        overall_risk = self._calculate_overall_risk(risk_levels)
        
        # D√©terminer si le mod√®le est tradable
        is_tradable = self._is_model_tradable(metrics_analysis, overall_grade, overall_risk)
        
        # Calculer le score de confiance
        confidence_score = self._calculate_confidence_score(metrics_analysis)
        
        # Identifier les forces et faiblesses
        key_strengths = self._identify_strengths(metrics_analysis)
        key_weaknesses = self._identify_weaknesses(metrics_analysis)
        
        # G√©n√©rer les recommandations
        recommendations = self._generate_recommendations(metrics_analysis, overall_grade, overall_risk)
        
        # G√©n√©rer les avertissements
        warnings = self._generate_warnings(metrics_analysis, overall_risk)
        
        return ModelAnalysis(
            model_name=model_name,
            overall_grade=overall_grade,
            risk_level=overall_risk,
            is_tradable=is_tradable,
            confidence_score=confidence_score,
            key_strengths=key_strengths,
            key_weaknesses=key_weaknesses,
            recommendations=recommendations,
            warnings=warnings,
            metrics_analysis=metrics_analysis
        )
    
    def _calculate_overall_grade(self, grades: List[PerformanceGrade]) -> PerformanceGrade:
        """Calcule la note globale bas√©e sur les notes individuelles"""
        if not grades:
            return PerformanceGrade.FAILING
        
        # Mapping des notes vers des valeurs num√©riques
        grade_values = {
            PerformanceGrade.EXCELLENT: 5,
            PerformanceGrade.VERY_GOOD: 4,
            PerformanceGrade.GOOD: 3,
            PerformanceGrade.AVERAGE: 2,
            PerformanceGrade.POOR: 1,
            PerformanceGrade.FAILING: 0
        }
        
        avg_value = sum(grade_values[grade] for grade in grades) / len(grades)
        
        if avg_value >= 4.5:
            return PerformanceGrade.EXCELLENT
        elif avg_value >= 3.5:
            return PerformanceGrade.VERY_GOOD
        elif avg_value >= 2.5:
            return PerformanceGrade.GOOD
        elif avg_value >= 1.5:
            return PerformanceGrade.AVERAGE
        elif avg_value >= 0.5:
            return PerformanceGrade.POOR
        else:
            return PerformanceGrade.FAILING
    
    def _calculate_overall_risk(self, risk_levels: List[RiskLevel]) -> RiskLevel:
        """Calcule le niveau de risque global"""
        if not risk_levels:
            return RiskLevel.CRITICAL
        
        # Prendre le niveau de risque le plus √©lev√©
        risk_values = {
            RiskLevel.VERY_LOW: 1,
            RiskLevel.LOW: 2,
            RiskLevel.MEDIUM: 3,
            RiskLevel.HIGH: 4,
            RiskLevel.VERY_HIGH: 5,
            RiskLevel.CRITICAL: 6
        }
        
        max_risk_value = max(risk_values[risk] for risk in risk_levels)
        
        for risk, value in risk_values.items():
            if value == max_risk_value:
                return risk
    
    def _is_model_tradable(self, metrics_analysis: Dict[str, MetricInterpretation], 
                          overall_grade: PerformanceGrade, overall_risk: RiskLevel) -> bool:
        """D√©termine si le mod√®le est utilisable pour du trading r√©el"""
        
        # Crit√®res stricts pour la tradabilit√©
        if overall_risk == RiskLevel.CRITICAL:
            return False
        
        if overall_grade == PerformanceGrade.FAILING:
            return False
        
        # V√©rifier les m√©triques critiques
        critical_metrics = ['sharpe_ratio', 'total_return']
        for metric_name in critical_metrics:
            if metric_name in metrics_analysis:
                metric = metrics_analysis[metric_name]
                if metric.risk_level == RiskLevel.CRITICAL:
                    return False
        
        return True
    
    def _calculate_confidence_score(self, metrics_analysis: Dict[str, MetricInterpretation]) -> float:
        """Calcule un score de confiance global (0-1)"""
        if not metrics_analysis:
            return 0.0
        
        # Poids des m√©triques
        weights = {
            'sharpe_ratio': 0.25,
            'total_return': 0.20,
            'max_drawdown': 0.15,
            'win_rate': 0.15,
            'accuracy': 0.15,
            'f1_score': 0.10
        }
        
        total_score = 0.0
        total_weight = 0.0
        
        for metric_name, metric in metrics_analysis.items():
            if metric_name in weights:
                weight = weights[metric_name]
                # Convertir la note en score (0-1)
                grade_scores = {
                    PerformanceGrade.EXCELLENT: 1.0,
                    PerformanceGrade.VERY_GOOD: 0.8,
                    PerformanceGrade.GOOD: 0.6,
                    PerformanceGrade.AVERAGE: 0.4,
                    PerformanceGrade.POOR: 0.2,
                    PerformanceGrade.FAILING: 0.0
                }
                
                score = grade_scores[metric.grade]
                total_score += score * weight
                total_weight += weight
        
        return total_score / total_weight if total_weight > 0 else 0.0
    
    def _identify_strengths(self, metrics_analysis: Dict[str, MetricInterpretation]) -> List[str]:
        """Identifie les forces du mod√®le"""
        strengths = []
        
        for metric_name, metric in metrics_analysis.items():
            if metric.grade in [PerformanceGrade.EXCELLENT, PerformanceGrade.VERY_GOOD]:
                if metric_name == 'sharpe_ratio':
                    strengths.append("Excellent √©quilibre rendement/risque")
                elif metric_name == 'total_return':
                    strengths.append("Rendements √©lev√©s et consistants")
                elif metric_name == 'max_drawdown':
                    strengths.append("Faible volatilit√© et stabilit√©")
                elif metric_name == 'win_rate':
                    strengths.append("Taux de r√©ussite √©lev√©")
                elif metric_name == 'accuracy':
                    strengths.append("Pr√©cision ML exceptionnelle")
        
        return strengths
    
    def _identify_weaknesses(self, metrics_analysis: Dict[str, MetricInterpretation]) -> List[str]:
        """Identifie les faiblesses du mod√®le"""
        weaknesses = []
        
        for metric_name, metric in metrics_analysis.items():
            if metric.grade in [PerformanceGrade.POOR, PerformanceGrade.FAILING]:
                if metric_name == 'sharpe_ratio':
                    weaknesses.append("Mauvais √©quilibre rendement/risque")
                elif metric_name == 'total_return':
                    weaknesses.append("Rendements insuffisants ou n√©gatifs")
                elif metric_name == 'max_drawdown':
                    weaknesses.append("Volatilit√© excessive")
                elif metric_name == 'win_rate':
                    weaknesses.append("Taux de r√©ussite faible")
                elif metric_name == 'accuracy':
                    weaknesses.append("Pr√©cision ML insuffisante")
        
        return weaknesses
    
    def _generate_recommendations(self, metrics_analysis: Dict[str, MetricInterpretation], 
                                overall_grade: PerformanceGrade, overall_risk: RiskLevel) -> List[str]:
        """G√©n√®re des recommandations sp√©cifiques"""
        recommendations = []
        
        # Recommandations bas√©es sur la note globale
        if overall_grade == PerformanceGrade.EXCELLENT:
            recommendations.append("‚úÖ Mod√®le recommand√© pour un usage intensif")
            recommendations.append("üí° Consid√©rer pour l'automatisation compl√®te")
        elif overall_grade == PerformanceGrade.VERY_GOOD:
            recommendations.append("‚úÖ Mod√®le recommand√© pour la plupart des strat√©gies")
            recommendations.append("üìä Surveiller les performances r√©guli√®rement")
        elif overall_grade == PerformanceGrade.GOOD:
            recommendations.append("‚ö†Ô∏è Mod√®le utilisable avec prudence")
            recommendations.append("üîç Surveiller attentivement les m√©triques")
        elif overall_grade == PerformanceGrade.AVERAGE:
            recommendations.append("‚ùå Mod√®le non recommand√© pour le trading r√©el")
            recommendations.append("üõ†Ô∏è Am√©liorer avant utilisation")
        else:
            recommendations.append("üö® ARR√äTER imm√©diatement l'utilisation")
            recommendations.append("üîß Refonte compl√®te n√©cessaire")
        
        # Recommandations sp√©cifiques par m√©trique
        for metric_name, metric in metrics_analysis.items():
            if metric.risk_level == RiskLevel.CRITICAL:
                if metric_name == 'sharpe_ratio':
                    recommendations.append("üéØ R√©viser compl√®tement la logique de trading")
                elif metric_name == 'total_return':
                    recommendations.append("üí∞ Arr√™ter imm√©diatement - pertes importantes")
                elif metric_name == 'max_drawdown':
                    recommendations.append("üìâ Impl√©menter des stop-loss stricts")
        
        return recommendations
    
    def _generate_warnings(self, metrics_analysis: Dict[str, MetricInterpretation], 
                         overall_risk: RiskLevel) -> List[str]:
        """G√©n√®re des avertissements de s√©curit√©"""
        warnings = []
        
        if overall_risk == RiskLevel.CRITICAL:
            warnings.append("üö® ALERTE CRITIQUE: Ce mod√®le pr√©sente un risque extr√™me")
            warnings.append("‚ö†Ô∏è Ne pas utiliser pour du trading r√©el")
        
        # Avertissements sp√©cifiques
        for metric_name, metric in metrics_analysis.items():
            if metric.risk_level == RiskLevel.CRITICAL:
                if metric_name == 'sharpe_ratio':
                    warnings.append("‚ö†Ô∏è Sharpe Ratio n√©gatif - le mod√®le fait perdre de l'argent")
                elif metric_name == 'total_return':
                    warnings.append("‚ö†Ô∏è Rendement n√©gatif - perte de capital confirm√©e")
                elif metric_name == 'max_drawdown':
                    warnings.append("‚ö†Ô∏è Drawdown critique - risque de perte majeure")
        
        return warnings
